---
title: Lecture 6
subtitle: Group Operations; Reshaping & Joining `DataFrames`
format:
  clean-revealjs:
    self-contained: true
    incremental: true
    #### logo: logo-title-slide.png
author:
  - name: Byeong-Hak Choe
    email: bchoe@geneseo.edu
    affiliations: SUNY Geneseo
date: 2024-03-12
callout-icon: false
execute: 
  eval: false
  echo: true
#### bibliography: refs.bib
include-after-body: target-hover.html
---


```{r setup}
#| include: false
#| eval: true

library(knitr)
library(tidyverse)
#### set default options
opts_chunk$set(echo = FALSE,
               fig.width = 7.252,
               fig.height = 4,
               comment = "####",
               dpi = 300)

knitr::knit_engines$set("markdown")
```


## Learning Objectives


- Primer on Custom Functions
- Group Operations
- Reshaping `DataFrames`
- Joining `DataFrames`


# Primer on Custom Functions {background-color="#1c4982"}


## Python Basics
### Primer on Custom Functions


- A function can take any number and type of input *parameters* and return any number and type of output *results*.

- We can do two things with a function:
  - *Define* it
  - *Call* it


## Python Basics
### Primer on Custom Functions

:::{.nonincremental}

- To define a Python function, we type `def`, the function name, parentheses enclosing any input **parameters** to the function, and then finally, a colon (`:`). 

- Let's *define* a very simple function `my_half()` that has a *parameter* `x` and *returns* a value `x / 2`.

:::

```{.python}
def my_half(x):
    return x / 2
    
my_half(2)
```

- The values we pass into the function when we call it are known as *arguments*. 

- When we call a function with arguments, the values of those arguments are copied to their corresponding *parameters* inside the function.



## Python Basics
### Primer on Custom Functions - Lambda Functions

- A Python *lambda* function is an *anonymous* function expressed as a single statement.
  - It is defined with the *lambda* keyword, which has no meaning other than “we are declaring an anonymous function”:

```{.python}
def my_half(x):
    return x / 2
    
equiv_my_half = lambda x: x / 2

my_half(2)
equiv_my_half(2)
```




# Group Operations {background-color="#1c4982"}

## Group Operations
### Fortune 1000 dataset

:::{.nonincremental}

- The Fortune 1000 is a listing of the 1,000 largest companies in the United States by revenue.
  - The list is updated annually by the business magazine *Fortune*.
  - The `fortune_2023.csv` file is a collection of Fortune 1000 companies from 2023 (*Source*: [*Kaggle*](https://www.kaggle.com/datasets/jeannicolasduval/2023-fortune-1000-companies-info)).

:::

```{.python}
fortune1000 = pd.read_csv("https://bcdanl.github.io/data/fortune_2023.csv")

varlist = ['Company', 'Revenues_M', 'Profits_M', 'Number_of_employees', 'Sector', 'Industry']
fortune = fortune1000[varlist]
```

- A sector can have many companies; An industry is a subcategory within a sector.
- Let's explore the `fortune` `DataFrame`.
  - How many unique sectors are in `fortune`?


## Group Operations
### Creating a `GroupBy` object from a dataset

:::{.nonincremental}

- Let's pull out all companies with a `Sector` value of `"Retailing"`.
  - Then, calculate the Retailing sector’s average revenue:
  
:::

```{.python}
in_retailing = ( fortune["Sector"] == "Retailing" )
retail_companies = fortune[ in_retailing ]
retail_companies["Revenues"].mean()

```

- Without a group operation, we may need to write a lot of additional code to apply the same logic to the other 20 sectors in `fortune`.
  - Pandas' `GroupBy` object offers the best solution out of the box.


## Group Operations
### Creating a `GroupBy` object from a dataset


```{.python}
sectors = fortune.groupby("Sector")
len(sectors)    # fortune["Sector"].nunique()
sectors.size()
```

- We can count the number of groups in sectors by passing the `GroupBy` object into the Python's built-in `len()` function

- The `size()` method on the `GroupBy` object returns a `Series` with an alphabetical list of the groups and their observation counts.

## Group Operations
### Attributes and methods of a `GroupBy` object


```{.python}
sectors.groups
```

- The `groups` attribute stores a dictionary with associations of group-to-observations.



## Group Operations
### Attributes and methods of a `GroupBy` object

:::{.nonincremental}

- What if we want to find the highest-performing company (by revenue) within each sector? 

:::

```{.python}
sectors.first()
sectors.last()
```

- The `GroupBy` object’s `first()/last()` method extracts the first/last observation listed for each group in a `DataFrame`. 
  - Since our `fortune` `DataFrame` is sorted by `Revenue_M`, the first company pulled out for each sector will be the highest-performing company within that sector.
  

## Group Operations
### Attributes and methods of a `GroupBy` object


```{.python}
sectors.nth(0)
sectors.nth(1)
fortune[fortune["Sector"] == "Apparel"]
```

- The `nth()` method is used with a `GroupBy` object to select the nth observation from each group. 
  - Here we can confirm the output is correct by filtering for the "Apparel" observations in `fortune`.

## Group Operations
### Attributes and methods of a `GroupBy` object


```{.python}
sectors.head(2)
sectors.tail(2)
```

- The `head(n)/tail(n)` method extracts the first/last `n` observations from each group.

## Group Operations
### Attributes and methods of a `GroupBy` object


```{.python}
sectors.get_group("Energy")
type( sectors.get_group("Energy") )
```

- We can use the `get_group()` method to extract all observations in a given group. 
  - The method returns a `DataFrame` containing the observations.

## Group Operations
### Aggregation

:::{.nonincremental}
- We can invoke methods on the `GroupBy` object to apply aggregate operations to every group.
  -  Aggregation is the process of taking multiple values and returning a single value.

:::

```{.python}
sectors.sum()
sectors.mean()
```



## Group Operations
### Aggregation


```{.python}
sectors["Revenues_M"]
sectors["Revenues_M"].sum()
sectors["Revenues_M"].mean()
sectors["Revenues_M"].max()
sectors["Revenues_M"].min()
```

- We can target a single variable by passing its name inside square brackets after the `GroupBy` object. 
  - Pandas returns a new object, a `SeriesGroupBy`.



## Group Operations
### Aggregation

```{.python}
sectors["Revenues_M"]  # this is a SeriesGroupBy object
sectors["Revenues_M"].agg('sum')
sectors["Revenues_M"].agg('mean')
sectors["Revenues_M"].agg('max')
sectors["Revenues_M"].agg('min')
```

- The `agg()` method can also be used on a `SeriesGroupBy`.
- Instead of directly calling the aggregation method, we can call the `agg()` method, and pass the aggregation method we want in there.


## Group Operations
### Aggregation


```{.python}
sectors.agg(
  Revenues_M_min = ("Revenues_M", "min"),
  Profits_M_max = ("Profits_M", "max"),
  Number_of_employees_mean = ("Revenues_M", "mean")
)
```

- The `agg()` method can apply multiple aggregate operations to different variables and can accept a tuple as its argument.



## Group Operations
### Aggregation


<p align="center">
  <img src="https://bcdanl.github.io/lec_figs/pandas-agg-methods.png" width="550">
</p>

- We pass in whatever aggregation we want. 
  - Some common options are in the table above.



## Group Operations

Let's do Questions 1-6 in Part 1 of [Classwork 6](https://bcdanl.github.io/module-1/danl-cw/danl-m1-cw-6.html)!


## Group Operations
### Add a New Variable with `GroupBy.transform()`

:::{.nonincremental}
- Just like the `agg()` method, the `transform()` method can accept the aggregation method (e.g., `'sum'`, `'mean'`).

- Unlike the `agg()` method, the `transform()` method does not collapse `DataFrame` and goes back to the original index.

:::

```{.python}
sectors['Revenues_M'].transform('min')
sectors['Profits_M'].transform('max')
sectors['Number_of_employees'].transform('mean')
```



## Group Operations
### Add a New Variable with `GroupBy.transform()`

```{.python}
fortune['Revenues_M_min'] = sectors['Revenues_M'].transform('min')
fortune['Profits_M_max'] = sectors['Profits_M'].transform('max')
fortune['Number_of_employees_mean'] = sectors['Number_of_employees'].transform('mean')
```

- Since the `transform()` method returns a `Series` with the index label that is the same as in the original `DataFrame`, it can be used to add a new variable to the original `DataFrame`.


## Group Operations
### Add New Variables with `assign()` and `GroupBy.transform()` 

```{.python}
sectors = fortune.groupby("Sector")

fortune = fortune.assign(
    Revenues_M_min = sectors['Revenues_M'].transform('min'),
    Profits_M_max = sectors['Profits_M'].transform('max'),
    Number_of_employees_mean = sectors['Number_of_employees'].transform('mean')
)
```



## Group Operations
### `agg()` vs. `transform()`

- Use `.agg()` with `.groupby()` when you want to take multiple values and return a single (aggregated) value for *each group*.
  - Groups become the new index labels.

- Use `.transform()` with `.groupby()` when you want to perform computations on your groups but you want to return a single (aggregated) value for *each observation*.
  -  That is, `.transform()` does not collapse the `DataFrame`.



## Group Operations

Let's do Question 7 of [Classwork 7](https://bcdanl.github.io/210/danl-cw/danl-210-cw-07.html)!



## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- Suppose that we want to apply a custom operation to each group in a `GroupBy` object.
  - For practice, let’s now shuffle observations in `fortune`.
:::

```{.python}
fortune = (
    fortune
    .sample( frac = 1 )
    .reset_index( drop = True )
)
```

- `sample(frac=1)`: This samples 100% of the observations from the `DataFrame`, effectively shuffling it. 
  - The `frac` parameter specifies the fraction of observations to return in the random sample, so `frac=1` means "return all observations".



## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- Suppose that we want to apply a custom operation to each group in a `GroupBy` object.
  - For practice, let’s now shuffle observations in `fortune`.
  
:::

```{.python}
fortune_shuffled = (
    fortune
    .sample( frac = 1 )
    .reset_index( drop = True )
)
```

- `reset_index()`: This resets the index of the `DataFrame`. 
  - The `drop = True` option is used to prevent the old index from being added as a variable in the new `DataFrame`.




## Group Operations
### Applying a Custom Operation to All Groups

- How can we identify top 5 companies in each sector?
  1. `sort_values()` with `groupby()`
  2. `nlargest()` with `groupby()`

- However, `DataFrameGroupBy` has no methods `sort_values()` or `nlargest()`.


## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- How can we apply the `nlargest()` method to each group?
  - First, define a *custom function* that accepts a single argument: a `DataFrame`.
  - Second, pass the `apply()` method the custom function.
  
:::

```{.python}
def get_largest_obs(df):
    return df.nlargest(1, "Revenues_M", keep="all")

sectors.apply(get_largest_obs)

# labmda function
sectors.apply(lambda df: df.nlargest(1, "Revenues_M", keep="all"))
```

- We can use the `apply()` method when pandas does not support a custom aggregation we would like to apply to each group.



## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- To rewrite the `get_largest_obs` function as a lambda function, we would define it as follows:

:::

```{.python}
def get_largest_obs(df):
    return df.nlargest(1, "Revenues_M", keep="all")

sectors.apply(lambda df: df.nlargest(1, "Revenues_M", keep="all"))
```

- We can use the `apply()` method when pandas does not support a custom aggregation we would like to apply to each group.


## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- To rewrite our `get_largest_obs` function as a lambda function with the `apply()` method, we can do the following. 
  
:::

```{.python}
sectors.apply(lambda df: df.nlargest(1, "Revenues_M", keep="all"))
```


## Group Operations
### Applying a Custom Operation to All Groups


:::{.nonincremental}
- How can we apply a custom function with multiple parameters to a `GroupBy` object?
  
:::

```{.python}
def get_nlargest_obs(df, n, var):
  return df.nlargest(n, var, keep = "all")

sectors.apply(get_nlargest_obs, 2, "Revenues_M")
```

- When applying a custom function with multiple parameters to a `GroupBy` object, we need to provide the rest of arguments to the `apply()` method.




## Group Operations
### Applying a Custom Operation to All Groups

:::{.nonincremental}
- Can we apply a lambda function with multiple parameters to a `GroupBy` object?
  
:::

```{.python}
sectors.apply(lambda df: df.nlargest(2, "Revenues_M", keep="all"))
```

- Lambda functions do not support passing additional parameters directly in the `apply()` method!
  -  We would typically need to provide arguments to additional parameters within the lambda function.  




## Group Operations
### Grouping by Multiple Variables


```{.python}
sector_and_industry = fortune.groupby(["Sector", "Industry"])
```

- We can create a `GroupBy` object with values from multiple variables. 
  - This operation is optimal when a combination of variables serves as the best identifier for a group.

## Group Operations
### Grouping by Multiple Variables


```{.python}
(
    sector_and_industry
    .size()
    .reset_index(name = "n")
)
```

- The `GroupBy` object’s `size()` method now returns a `MultiIndex Series` with a count of observations for each internal group.

- The `reset_index()` method can be used to convert a `Series` into a `DataFrame`.
  - The `name` option renames a variable of index when resetting index.


## Group Operations
### Grouping by Multiple Variables


```{.python}
sector_and_industry.get_group(("Business Services", "Financial Data Services"))
```

- The `get_group()` method requires a *tuple* of values to extract a nested `DataFrame` from the `GroupBy` collection.



## Group Operations
### Grouping by Multiple Variables

```{.python}
sector_and_industry.sum()
sector_and_industry["Revenues_M"].mean()

(
    sector_and_industry["Revenues_M"]
    .mean()
    .reset_index(name = "Revenues_mean")
)
```

- For all aggregations, pandas returns a `MultiIndex DataFrame` with the calculations.




## Group Operations

Let's do Question 7 in Part 1 of [Classwork 6](https://bcdanl.github.io/module-1/danl-cw/danl-m1-cw-6.html)!




# Reshaping `DataFrames` {background-color="#1c4982"}




## Reshaping `DataFrames`

- A data set can be given in a format unsuited for the analysis that we would like to perform on it.






## Reshaping `DataFrames`

<p align="center">
  <img src="https://bcdanl.github.io/lec_figs/pandas-melt-pivot.gif" width="400px">
</p>



# Joining `DataFrames` {background-color="#1c4982"}


## Joining `DataFrames`

<p align="center">
  <img src="https://bcdanl.github.io/lec_figs/pandas-melt-pivot.gif" width="400px">
</p>


