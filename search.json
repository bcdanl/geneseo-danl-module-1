[
  {
    "objectID": "listing-danl-m1-qa.html",
    "href": "listing-danl-m1-qa.html",
    "title": "DANL Module 1 - Lecture Discussion",
    "section": "",
    "text": "Title\n\n\nDate\n\n\n\n\n\n\nWeek 1 - Q & A\n\n\nFebruary 6, 2024\n\n\n\n\nWeek 2 - Q & A\n\n\nFebruary 13, 2024\n\n\n\n\nWeek 3 - Q & A\n\n\nFebruary 20, 2024\n\n\n\n\nWeek 4 - Q & A\n\n\nFebruary 27, 2024\n\n\n\n\nWeek 5 - Q & A\n\n\nMarch 5, 2024\n\n\n\n\nWeek 6 - Q & A\n\n\nMarch 12, 2024\n\n\n\n\nWeek 7 - Q & A\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-1.html",
    "href": "danl-hw/danl-m1-hw-1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Direction\n\nPlease submit your Jupyter Notebook for Homework 1 to the Brightspace with the name below:\n\ndanl-m1-hw1-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m1-hw1-choe-byeonghak.ipynb )\n\nThe due is February 13, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nWrite a Python Notebook (*.ipynb) to answer each question.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question.\n\n\n\n\n\nQuestion 1\nHow do you assign the value 5 to a variable named x?\nAnswer\n\n\n\nQuestion 2\nGiven lst = [1, 2, 3, 4, 5], what does lst[1:4] return?\nAnswer\n\n\n\nQuestion 3\n\nHow do you create a dictionary with keys \"apple\", \"banana\", and \"cherry\", each with the corresponding values 5, 3, and 7?\nHow do you access the value associated with the key \"banana\" in the dictionary created above?\n\nAnswer\n\n\n\nQuestion 4\nFor the expressions below, what is the value of the expression? Explain thoroughly.\n\nTrue and False\n\n\nTrue or False\n\n\nnot (100 == '100' and 25 &lt; 36)\n\nAnswer\n\n\n\nQuestion 5\n\nCreate a new if-elif-else chain that prints \"well done\" if a score is over 90, “good” if between 40 and 90, and \"bad luck\" otherwise.\n\nAnswer\n\n\n\nQuestion 6\nWrite a for loop that prints out \"coding for data analysts\" so that each word is printed in a successive iteration.\nAnswer\n\n\n\nQuestion 7\n\nHow do you import the math module in a Python script?\nAfter importing math, how do you use its sqrt function to find the square root of 16?\n\nAnswer\n\n\n\nQuestion 8\n\nDo Question 6 in Classwork 1\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html",
    "href": "danl-hw/danl-m1-hw-2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Homework 2 to the Brightspace with the name below:\n\ndanl-m1-hw2-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m2-hw2-choe-byeonghak.ipynb )\n\nThe due is February 20, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nPlease prepare a Jupyter/Python Notebook (*.ipynb) to address all questions.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#variable-description",
    "href": "danl-hw/danl-m1-hw-2.html#variable-description",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\nid_player: Player ID\nBorn: Date of Birth\nCity: City of Birth\nCntry: Country of Birth\nNat: Nationality\nLast_Name: Last name\nFirst_name: First Name\nPosition: Position\nTeam: Team\nGP: The number of games\nG: The number of goals\nA: The number of assists\nTOI: The total time on ice (in second)\nTOI_GP: Average amount of playing time per game (in minute)"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#question-1",
    "href": "danl-hw/danl-m1-hw-2.html#question-1",
    "title": "Homework 2",
    "section": "Question 1",
    "text": "Question 1\nHow many players had at least some ice time?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#question-2",
    "href": "danl-hw/danl-m1-hw-2.html#question-2",
    "title": "Homework 2",
    "section": "Question 2",
    "text": "Question 2\nWho is the top scorer in terms of goals?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#question-3",
    "href": "danl-hw/danl-m1-hw-2.html#question-3",
    "title": "Homework 2",
    "section": "Question 3",
    "text": "Question 3\nHow can we count the number of NHL players for each country?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#question-4",
    "href": "danl-hw/danl-m1-hw-2.html#question-4",
    "title": "Homework 2",
    "section": "Question 4",
    "text": "Question 4\n\nHow many unique countries are in nhl.csv?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-2.html#question-5",
    "href": "danl-hw/danl-m1-hw-2.html#question-5",
    "title": "Homework 2",
    "section": "Question 5",
    "text": "Question 5\nWhich three nationalities have the highest number of players?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-exam.html",
    "href": "danl-hw/danl-m1-exam.html",
    "title": "Take-home Exam",
    "section": "",
    "text": "Direction\n\nWrite a Python code to answer each question.\nMake at least some simple comment (# ...) in each question.\nImport Python libraries you need here.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html",
    "href": "danl-hw/danl-m1-hw-4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Homework 4 to the Brightspace with the name below:\n\ndanl-m1-hw4-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m1-hw4-choe-byeonghak.ipynb )\n\nThe due is March 5, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nPlease prepare a Jupyter/Python Notebook (*.ipynb) to address all questions.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#variable-description",
    "href": "danl-hw/danl-m1-hw-4.html#variable-description",
    "title": "Homework 4",
    "section": "Variable Description",
    "text": "Variable Description\n\nFiscal Year: Fiscal Year;\nPayroll Number: Payroll Number;\nAgency Name: The Payroll agency that the employee works for;\nLast Name: Last name of employee;\nFirst Name: First name of employee;\nMid Init: Middle initial of employee;\nAgency Start Date: Date which employee began working for their current agency;\nWork Location Borough: Borough of employee’s primary work location;\nTitle Description: Civil service title description of the employee;\nLeave Status as of June 30: Status of employee as of the close of the relevant fiscal year;\nBase Salary: Base Salary assigned to the employee;\nPay Basis: Lists whether the employee is paid on an hourly, per diem or annual basis;\nRegular Hours: Number of regular hours employee worked in the fiscal year;\nRegular Gross Paid: The amount paid to the employee for base salary during the fiscal year;\nOT Hours: Overtime Hours worked by employee in the fiscal year;\nTotal OT Paid: Total overtime pay paid to the employee in the fiscal year;\nTotal Other Pay: Includes any compensation in addition to gross salary and overtime pay, ie Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-1",
    "href": "danl-hw/danl-m1-hw-4.html#question-1",
    "title": "Homework 4",
    "section": "Question 1",
    "text": "Question 1\n\nHow many employees have a “Base Salary” within the top 10% of the DataFrame?\n\nHint: The .quantile() method can be useful.\n\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-2",
    "href": "danl-hw/danl-m1-hw-4.html#question-2",
    "title": "Homework 4",
    "section": "Question 2",
    "text": "Question 2\nFilter the DataFrame for employees who have “OT Hours” greater than 0 but less than 100, and their “Leave Status as of June 30” is “ACTIVE”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-3",
    "href": "danl-hw/danl-m1-hw-4.html#question-3",
    "title": "Homework 4",
    "section": "Question 3",
    "text": "Question 3\nFind the unique job titles in the “DEPARTMENT OF EDUCATION ADMIN” agency and count how many there are.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-4",
    "href": "danl-hw/danl-m1-hw-4.html#question-4",
    "title": "Homework 4",
    "section": "Question 4",
    "text": "Question 4\n\nIdentify the employee(s) with the highest “Total OT Paid” in the DataFrame.\n\nInclude their “First Name”, “Last Name”, and “Total OT Paid”.\n\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#variable-description-1",
    "href": "danl-hw/danl-m1-hw-4.html#variable-description-1",
    "title": "Homework 4",
    "section": "Variable Description",
    "text": "Variable Description\n\npid: playlist ID; unique ID for playlist\nplaylist_name: a name of playlist\npos: a position of the track within a playlist (starting from 0)\nartist_name: name of the track’s primary artist\ntrack_name: name of the track\nduration_ms: duration of the track in milliseconds\nalbum_name: name of the track’s album"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-5",
    "href": "danl-hw/danl-m1-hw-4.html#question-5",
    "title": "Homework 4",
    "section": "Question 5",
    "text": "Question 5\n\nFind the five most popular song.\n\nA value of a song is defined as a combination of a artist_name value and a track_name value.\nWho are artists for those five most popular song?\n\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-4.html#question-6",
    "href": "danl-hw/danl-m1-hw-4.html#question-6",
    "title": "Homework 4",
    "section": "Question 6",
    "text": "Question 6\n\nCreate a DataFrame that only contains observations from playlists featuring the song “One Dance” by Drake.\n\nNext, identify the song with the highest popularity after Drake’s “One Dance” in the newly created DataFrame.\n\n\nAnswer"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-03.html",
    "href": "danl-qa/danl-m1-qa-03.html",
    "title": "Week 3 - Q & A",
    "section": "",
    "text": "Welcome to our Week 3 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 3, including Lecture 3 slides, Classwork 3, and Homework Assignment 3.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 3 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-01.html",
    "href": "danl-qa/danl-m1-qa-01.html",
    "title": "Week 1 - Q & A",
    "section": "",
    "text": "Welcome to our Week 1 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 1, including Lecture 1 slides, Classwork 1, and Homework Assignment 1.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 1 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-04.html",
    "href": "danl-qa/danl-m1-qa-04.html",
    "title": "Week 4 - Q & A",
    "section": "",
    "text": "Welcome to our Week 4 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 4, including Lecture 4 slides, Classwork 4, and Homework Assignment 1.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 4 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-07.html",
    "href": "danl-qa/danl-m1-qa-07.html",
    "title": "Week 7 - Q & A",
    "section": "",
    "text": "Welcome to our Week 7 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 7, including Lecture 7 slides and Classwork 7.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 7 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "listing-danl-m1-lec.html",
    "href": "listing-danl-m1-lec.html",
    "title": "DANL Module 1 - Lecture",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus, Course Outline, Python Basics\n\n\nFebruary 6, 2024\n\n\n\n\nLecture 2\n\n\nPandas Basics - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\n\n\nFebruary 13, 2024\n\n\n\n\nLecture 3\n\n\nPandas Basics - Sorting & Indexing Data; Mathematical & Vectorized Operations\n\n\nFebruary 20, 2024\n\n\n\n\nLecture 4\n\n\nConverting Data Types; Filtering by Conditions; Dealing with Missing Values\n\n\nFebruary 27, 2024\n\n\n\n\nLecture 5\n\n\nDealing with Missing Values and Duplicates; Group Operations\n\n\nMarch 5, 2024\n\n\n\n\nLecture 6\n\n\nTidy Data [Lecture 6 slides may be subject to change during the Module.]\n\n\nMarch 12, 2024\n\n\n\n\nLecture 7\n\n\nMissing Data and Time-series Data [Lecture 7 slides may be subject to change during the Module.]\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html",
    "href": "danl-cw/danl-m1-cw-1.html",
    "title": "Classwork 1",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer\n\n\n\n\nFor each expression below, what is the value of the expression? Explain thoroughly.\n\n20 == '20'\n\n\nx = 4.0\ny = .5\n\nx &lt; y or 3*y &lt; x\n\nAnswer\n\n\n\n\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\n\nThe total trip cost is: $12.80\n\n\nAnswer\n\n\n\n\n\nlist_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\n\nThe largest value in the list is: 1000\n\n\nAnswer\n\n\n\n\nImport the pandas library as pd\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-1",
    "href": "danl-cw/danl-m1-cw-1.html#question-1",
    "title": "Classwork 1",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-2",
    "href": "danl-cw/danl-m1-cw-1.html#question-2",
    "title": "Classwork 1",
    "section": "",
    "text": "For each expression below, what is the value of the expression? Explain thoroughly.\n\n20 == '20'\n\n\nx = 4.0\ny = .5\n\nx &lt; y or 3*y &lt; x\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-3",
    "href": "danl-cw/danl-m1-cw-1.html#question-3",
    "title": "Classwork 1",
    "section": "",
    "text": "fare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\n\nThe total trip cost is: $12.80\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-4",
    "href": "danl-cw/danl-m1-cw-1.html#question-4",
    "title": "Classwork 1",
    "section": "",
    "text": "list_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\n\nThe largest value in the list is: 1000\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-5",
    "href": "danl-cw/danl-m1-cw-1.html#question-5",
    "title": "Classwork 1",
    "section": "",
    "text": "Import the pandas library as pd\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#basic-syntax",
    "href": "danl-cw/danl-m1-cw-1.html#basic-syntax",
    "title": "Classwork 1",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nHeadings\nHeadings are created by adding one or more # symbols before your heading text. The number of # symbols indicates the level of the heading.\n# Heading 1\n## Heading 2\n### Heading 3\n\n\nEmphasis\nYou can make text bold by wrapping it with two asterisks **, and italic by using one asterisk *.\n*italic* or _italic_\n**bold** or __bold__\n\n\nLists\nUnordered lists are created using *, -, or +, while ordered lists are numbered.\n- Item 1\n- Item 2\n  - Subitem 2.1\n  - Subitem 2.2\n1. First item\n2. Second item\n\n\nLinks and Images\nLinks are created using [Link Text](URL), and images with ![Alt Text](Image URL).\n[DANL 210](https://bcdanl.github.io/210)\n![Geneseo Logo](https://bcdanl.github.io/img/geneseo-logo.gif)"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#advanced-syntax",
    "href": "danl-cw/danl-m1-cw-1.html#advanced-syntax",
    "title": "Classwork 1",
    "section": "Advanced Syntax",
    "text": "Advanced Syntax\n\nBlockquote\n&gt; Be yourself. Everyone else is already taken. - Oscar Wilde.\n\n\nEmojis\n\nA ton of markdown emojis are available here 😄 ( :smile: )\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\n\n\n\n\nCode Blocks\nCode blocks are created by using triple backticks (```). Optionally, you can specify the language for syntax highlighting.\n```\n\"string\"\n```\n```python\n# Python code block\nimport numpy as np\n```"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#question-6",
    "href": "danl-cw/danl-m1-cw-1.html#question-6",
    "title": "Classwork 1",
    "section": "Question 6",
    "text": "Question 6\n\nDo the following tasks on this Classwork 1 Discussion Board:\n\nBasic Syntax: Write a comment with your name, a heading, an unordered list, an ordered list, a link, and an image.\nAdvanced Syntax: Write a comment that includes a Python code block, a blockquote, and an emoji."
  },
  {
    "objectID": "danl-cw/danl-m1-cw-1.html#references",
    "href": "danl-cw/danl-m1-cw-1.html#references",
    "title": "Classwork 1",
    "section": "References",
    "text": "References\n\nQuarto Markdown Basics\nStart writing on GitHub"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-2.html",
    "href": "danl-cw/danl-m1-cw-2.html",
    "title": "Classwork 2",
    "section": "",
    "text": "Direction\n\n\n\nThe nfl.csv file (with its pathname https://bcdanl.github.io/data/nfl.csv) contains a list of players in the National Football League with similar Name, Team, Position, Birthday, and Salary variables in the nba.csv file we used in class.\n\nimport pandas as pd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\nHow can we read the nfl.csv file, and assign it to a DataFrame object, nfl?\nWhat is an effective way to convert the values in its Birthday variable to datetimes?\n\nAnswer:\n\n\n\nQuestion 2\nHow can we set the DataFrame index to store the player names?\nAnswer:\n\n\n\nQuestion 3\n\nHow many observations are in nfl?\nWhat are the mean, median, standard deviation, minimum, and maximum of Salary in nfl?\n\nAnswer:\n\n\n\nQuestion 4\n\nHow can we count the number of players per team in nfl?\nHow many unique teams are in nfl?\n\nAnswer:\n\n\n\nQuestion 5\n\nWho are the five highest-paid players?\nWho is the oldest player?\n\nAnswer:\n\n\n\nQuestion 6\nHow can we sort the DataFrame first by Team in alphabetical order and then by Salary in descending order?\nAnswer:\n\n\n\nQuestion 7\nWho is the oldest player on the Kansas City Chiefs roster, and what is his birthday?\nAnswer:\n\n\n\nDiscussion\nWelcome to our Classwork 2 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Classwork 2.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Classwork 2 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html",
    "href": "danl-cw/danl-m1-cw-7.html",
    "title": "Classwork 7",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#load-libraries",
    "href": "danl-cw/danl-m1-cw-7.html#load-libraries",
    "title": "Classwork 7",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q1a",
    "href": "danl-cw/danl-m1-cw-7.html#q1a",
    "title": "Classwork 7",
    "section": "Q1a",
    "text": "Q1a\nAdd the new variables, closing_quarter and closing_year, to the DataFrame banks. - closing_quarter: the quarter in which the bank closed (1, 2, 3, or 4) - closing_year: the year in which the bank closed\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q1b",
    "href": "danl-cw/danl-m1-cw-7.html#q1b",
    "title": "Classwork 7",
    "section": "Q1b",
    "text": "Q1b\nCount the number of banks that were closed for each pair of year-quarter.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q1c",
    "href": "danl-cw/danl-m1-cw-7.html#q1c",
    "title": "Classwork 7",
    "section": "Q1c",
    "text": "Q1c\nProvide both seaborn code and a simple comment to describe the quarterly trend of bank failure.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q2a",
    "href": "danl-cw/danl-m1-cw-7.html#q2a",
    "title": "Classwork 7",
    "section": "Q2a",
    "text": "Q2a\nAdd a variable, date_dt, which is a datetime type of Date variable, to the stock DataFrame.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q2b",
    "href": "danl-cw/danl-m1-cw-7.html#q2b",
    "title": "Classwork 7",
    "section": "Q2b",
    "text": "Q2b\n\nFor each year, find the two dates, for which\n\nTSLA’s Close was the highest of the year.\nTSLA’s Close was the lowest of the year.\n\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-7.html#q2c",
    "href": "danl-cw/danl-m1-cw-7.html#q2c",
    "title": "Classwork 7",
    "section": "Q2c",
    "text": "Q2c\n\nCalculate the gap between the two adjacent dates with the highest Close of the year.\nCalculate the gap between the two adjacent dates with the lowest Close of the year.\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html",
    "href": "danl-cw/danl-m1-cw-4.html",
    "title": "Classwork 4",
    "section": "",
    "text": "The netflix-2019.csv file (with its pathname https://bcdanl.github.io/data/netflix-2019.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video’s title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#direction",
    "href": "danl-cw/danl-m1-cw-4.html#direction",
    "title": "Classwork 4",
    "section": "",
    "text": "The netflix-2019.csv file (with its pathname https://bcdanl.github.io/data/netflix-2019.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video’s title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-1",
    "href": "danl-cw/danl-m1-cw-4.html#question-1",
    "title": "Classwork 4",
    "section": "Question 1",
    "text": "Question 1\nOptimize the DataFrame for limited memory use and maximum utility by using the astype() method.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-2",
    "href": "danl-cw/danl-m1-cw-4.html#question-2",
    "title": "Classwork 4",
    "section": "Question 2",
    "text": "Question 2\nFind all observations with a title of “Limitless”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-3",
    "href": "danl-cw/danl-m1-cw-4.html#question-3",
    "title": "Classwork 4",
    "section": "Question 3",
    "text": "Question 3\nFind all observations with a director of “Robert Altman” and a type of “Movie”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-4",
    "href": "danl-cw/danl-m1-cw-4.html#question-4",
    "title": "Classwork 4",
    "section": "Question 4",
    "text": "Question 4\nFind all observations with either a date_added of “2018-06-15” or a director of “Bong Joon Ho”.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-5",
    "href": "danl-cw/danl-m1-cw-4.html#question-5",
    "title": "Classwork 4",
    "section": "Question 5",
    "text": "Question 5\nFind all observations with a director of “Ethan Coen,”Joel Coen“, and”Quentin Tarantino“.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-6",
    "href": "danl-cw/danl-m1-cw-4.html#question-6",
    "title": "Classwork 4",
    "section": "Question 6",
    "text": "Question 6\nFind all observations with a date_added value between January 1, 2019 and February 1, 2019.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-7",
    "href": "danl-cw/danl-m1-cw-4.html#question-7",
    "title": "Classwork 4",
    "section": "Question 7",
    "text": "Question 7\nDrop all observations with a NaN value in the director variable.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-4.html#question-8",
    "href": "danl-cw/danl-m1-cw-4.html#question-8",
    "title": "Classwork 4",
    "section": "Question 8",
    "text": "Question 8\nIdentify the days when Netflix added only one movie to its catalog.\nAnswer:"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-1",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-1",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nBuilt-in Aggregation Methods\n\n(1)(2)(3)(4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe know we can calculate multiple summary statistics simultaneously with .describe().\n## group by continent and describe each group\ncontinent_describe = df.groupby('continent')[\"lifeExp\"].describe()\ncontinent_describe"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-2",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-2",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nAggregation Functions\nFunctions From Other Libraries\nWe can also use other libraries’ functions that are not listed in the previous tables. (e.g., numpy, scipy)\n## calculate the average life expectancy by continent\n## but use the np.mean function\ncont_le_agg = df.groupby('continent')[\"lifeExp\"].agg(np.mean)\nQ. Add a new variable, the log of lifeExp, using np.log to DataFrame df."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-3",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-3",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nAggregation Functions\n\n(1)(2)(3)(4)(5)\n\n\nSometimes we may want to perform a calculation that is not provided by Pandas or another library.\n\nLet’s create our own mean function with def.\n\ndef my_mean(values):\n  n = len(values)    ## get the total number of numbers for the denominator\n  sum = 0   ## start the sum at 0\n  for value in values:\n      sum += value   ## add each value to the running sum\n  return sum / n   ## return the summed values divided by the number of values\n\n\nWe can pass our custom function straight into the .agg() method with my_mean.\n## use our custom function into agg\nagg_my_mean = df.groupby('year')[\"lifeExp\"].agg(my_mean)\n\nagg_my_mean\n\n\nWe can write functions that take multiple parameters.\ndef my_mean_diff(values, diff_value):\n    \"\"\"Difference between the mean and diff_value\n    \"\"\"\n    n = len(values)\n    sum = 0\n    for value in values:\n        sum += value\n    mean = sum / n\n    return(mean - diff_value)\n\n\nUsing my_mean_diff, we will calculate the global average life expectancy, diff_value, and subtract it from each grouped value.\n## custom aggregation function with multiple parameters\nagg_mean_diff = (\n  df\n  .groupby(\"year\")[\"lifeExp\"]\n  .agg(my_mean_diff, diff_value = global_mean)\n)\n\n\nWhen we want to calculate multiple functions, we can pass the multiple functions into .agg()\n\n## calculate the count, mean, std of the lifeExp by continent\ngdf = (\n  df\n  .groupby(\"year\")\n  [\"lifeExp\"]\n  .agg([np.count_nonzero, np.mean, np.std])\n)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-4",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-4",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nUse a dict in .agg() on a Series\nWe can also pass .agg() a Python dictionary ({key : value}). - The results will differ depending on whether we are aggregating directly on a DataFrame or on a Series object. - When specifying a dict on a grouped DataFrame, the keys are the columns of the DataFrame, and the values are the functions used in the aggregated calculation.\ngdf_dict = df.groupby(\"year\").agg(\n  {\"lifeExp\": \"mean\",\n    \"pop\": \"median\",\n    \"gdpPercap\": \"median\"})"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-5",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-5",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nUse a dict in .agg() on a DataFrame\nTo have user-defined column names in the output of a grouped series calculation, we need to rename those columns.\n\n\ngdf = (\n  df\n  .groupby(\"year\")\n  [\"lifeExp\"]\n  .agg(\n    [\n      np.count_nonzero,\n      np.mean,\n      np.std,\n    ]\n  )\n\n  .rename(\n    columns={\n      \"count_nonzero\": \"count\",\n      \"mean\": \"avg\",\n      \"std\": \"std_dev\",\n    }\n  )\n  .reset_index() ## return a flat dataframe\n)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-6",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-6",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nTransform\nWhen we transform data, we pass values from our dataframe into a function.\n\nThe function then “transforms” the data.\nUnlike .agg(), which can take multiple values and return a single (aggregated) value, .transform() takes multiple values and returns a one-to-one transformation of the values.\nThat is, it does not reduce the amount of data."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-7",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-7",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nTransform (cont.)\n\nLet’s calculate the z-score of our life expectancy data by year. \\[\nz = \\frac{x - \\mu}{\\sigma}\n\\]\n\\(x\\) is a value in a variable\n\\(\\mu\\) is the average of a variable\n\\(\\sigma\\) is the standard deviation of a variable\n\n\\[\n\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}(x - \\mu)^{2}}\n\\]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-8",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-8",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nTransform (cont.)\nThe following is a function, my_zscore(x), that calculates a z-score using Pandas methods.\ndef my_zscore(x):\n  '''Calculates the z-score of provided data\n  'x' is a vector or series of values\n  '''\n  return((x - x.mean()) / x.std())"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-9",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-9",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nTransform (cont.)\nNow we can use this function to .transform() our data by group.\ntransform_z = df.groupby('year')[\"lifeExp\"].transform(my_zscore)\n\nNote that both df and transform_z have the same number of rows and data.\n\ndf.shape\ntransform_z.shape"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-10",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-10",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nTransform (cont.)\nThe scipy library has its own zscore() function.\nLet’s use its zscore() function in a .groupby() .transform() and compare it to what happens when we do not use .groupby().\nfrom scipy.stats import zscore\n## calculate a grouped zscore\nsp_z_grouped = df.groupby('year')[\"lifeExp\"].transform(zscore)\n\n## calculate a nongrouped zscore\nsp_z_nogroup = zscore(df[\"lifeExp\"])\n\ntransform_z.head()\nsp_z_grouped.head()\nsp_z_nogroup[:5]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-11",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-11",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nagg, transform, and apply: when to use each with a groupby\nWith all of the different options available, it can be confusing to know when to use the different functions available for performing groupby operations, namely: .agg, .transform, and .apply.\nHere are the key points to remember: - Use .agg when using a groupby, but you want your groups to become the new index. - Use .transform when using a groupby, but you want to retain your original index. - Use .apply when using a groupby, but you want to perform operations that will leave neither the original index nor an index of groups."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-12",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-12",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\n.filter()\n.filter() allows us to split our data by keys, and then perform some kind of boolean subsetting on the data.\n\nLet’s work with the tips data set from seaborn:\n\nimport seaborn as sns\ntips = sns.load_dataset('tips')\n\n## note the number of rows in the original data\ntips.shape\n\n\n## look at the frequency counts for the table size\ntips['size'].value_counts()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-13",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-13",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\n.filter() (cont.)\nSuppose we want each group to consist of 30 or more observations. - To accomplish this goal, we can use the .filter() method on a grouped operation.\n## filter the data such that each group has more than 30 observations\ntips_filtered = (\n  tips\n  .groupby(\"size\")\n  .filter( lambda x : x[\"size\"].count() &gt;= 30 )\n)\n\ntips_filtered.shape\ntips_filtered['size'].value_counts()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-14",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-14",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nThe pandas.core.groupby.DataFrameGroupBy object\nThe .agg(), .transform(), and .filter() methods are commonly used after the .groupby().\ntips_10 = sns.load_dataset('tips').sample(10, random_state=42)\nprint(tips_10)\n\nWe can choose to save just the groupby object without running any other .agg(), .transform(), or .filter() method on it.\n\n\n\n## save just the grouped object\ngrouped = tips_10.groupby('sex')\ngrouped\n\n## see the actual groups of the groupby\n## it returns only the index\ngrouped.groups  ## row numbers?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-15",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-15",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nGroup Calculations Involving Multiple Variables\n\nWe have been usually performing .groupby() calculations on a single column.\n\nIf we specify the calculation we want right after the .groupby(), however, Python will perform the calculation on all the columns it can and silently drop the rest.\n\n\n## calculate the mean on relevant columns\navgs = grouped.mean()\navgs\n\n## list all the columns\ntips_10.columns  ## not all the columns reported a mean."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-16",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-16",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nSelecting a Group\nIf we want to extract a particular group, we can use the .get_group() method, and pass in the group that we want.\n\nFor example, if we wanted the Female values:\n\n## get the 'Female' group\nfemale = grouped.get_group('Female')\nfemale"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-17",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-17",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nIterating Through Groups\n\nAnother benefit of saving just the groupby object is that we can then iterate through the groups individually.\nWe can iterate through our grouped values just like any other container (e.g., list, dictionary) in Python using a for-loop.\n\nfor sex_group in grouped:\n    print(sex_group)\n    \n## we can't really get the 0 element from the grouped object\nprint(grouped[0])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-18",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-18",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nIterating Through Groups (cont.)\n\nLet’s modify the for loop to just show the first element, along with some of the things we get when we loop over the grouped object.\n\n\n\nfor sex_group in grouped:\n    type(sex_group) ## tuple\n    len(sex_group) ## length \n\n    ## get the first element\n    first_element = sex_group[0]\n    first_element\n    type(sex_group[0])\n\n    ## get the second element\n    second_element = sex_group[1]\n    second_element\n    type(second_element)\n\n    ## print what we have\n    print(f'what we have:')\n    print(sex_group)\n\n    ## stop after first iteration\n    break"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-19",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-19",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nIterating Through Groups (cont.)\n\nThe option of iterating through groups with for-loop is available for us if we need to iterate through the groups one at a time."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-20",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-20",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nMultiple Groups\n\nWe can add multiple variables to the .groupby()\n\n## mean by sex and time\nbill_sex_time = tips_10.groupby(['sex', 'time'])\n\ngroup_avg = bill_sex_time.mean()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-21",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-21",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nFlattening the Results (.reset_index())\n\nLet’s look at the type of the group_avg we just calculated.\n\ntype(group_avg)\n\nIf we look at the columns and the index, we get what we expect.\n\ngroup_avg.columns\ngroup_avg.index"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-22",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-22",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nFlattening the Results (.reset_index())\n\nIf we want to get a regular flat DataFrame back, we can call the .reset_index() method on the results.\n\ngroup_method = tips_10.groupby(['sex', 'time']).mean().reset_index()\ngroup_method\n\nAlternatively, we can use the as_index = False parameter in the .groupby() method (it is True by default).\n\ngroup_param = tips_10.groupby(['sex', 'time'], as_index=False).mean()\ngroup_param"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-23",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-23",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nSometimes, we may want to chain calculations after a .groupby() method. - We can always “flatten” the results and then execute another .groupby() statement, but that may not always be the most efficient way of performing the calculation.\nDownload epi_sim.zip from the Files section in Canvas.\nLet’s begin with this epidemiological simulation data on influenza cases in Chicago.\n## notice that we can even read a compressed zip file of a csv\nintv_df = pd.read_csv('data/epi_sim.zip')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-24",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-24",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nThe data set includes six columns: - ig_type: edge type (type of relationship between two nodes in the network, such as “school” and “work”) - intervened: time in the simulation at which an intervention occurred for a given person (pid) - pid: simulated person’s ID number - rep: replication run (each set of simulation parameters was run multiple times) - sid: simulation ID - tr: transmissibility value of the influenza virus"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-25",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-25",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nLet’s count the number of interventions for each replicate, intervention time, and treatment value. - Here, we are counting the ig_type arbitrarily. - We just need a value to get a count of observations for the groups.\ncount_only = (\n  intv_df\n  .groupby([\"rep\", \"intervened\", \"tr\"])\n  [\"ig_type\"]\n  .count()\n)\n\ncount_only"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-26",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-26",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nNow that we’ve done a .groupby() .count(), we can perform an additional .groupby() that calculates the average value. - However, our initial .groupby() method does not return a regular flat DataFrame.\ntype(count_only)\nThe results take the form of a multi-index Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-27",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-27",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nIf we want to do another .groupby() operation, we have to pass in the levels parameter to refer to the multi-index levels. - Here we pass in [0, 1, 2] for the first, second, and third index levels, respectively.\ncount_mean = count_only.groupby(level=[0, 1, 2]).mean()\ncount_mean.head()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-28",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-28",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nWe can combine all of these operations in a single command.\ncount_mean = (\n    intv_df\n    .groupby([\"rep\", \"intervened\", \"tr\"])[\"ig_type\"]\n    .count()\n    .groupby(level=[0, 1, 2])\n    .mean()\n)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-29",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#groupby-operations-split-apply-combine-29",
    "title": "Lecture 5",
    "section": "Groupby Operations: Split-Apply-Combine",
    "text": "Groupby Operations: Split-Apply-Combine\nWorking With a MultiIndex\nSee how the relationship between intervened and ig_type varies by rep and tr.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfig = sns.lmplot(\n   data = count_mean.reset_index(),\n   x = \"intervened\",\n   y = \"ig_type\",\n   hue = \"rep\",\n   col = \"tr\",\n   fit_reg = False,\n   palette = \"viridis\" )\n   \nplt.show()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#instructor-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#instructor-1",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nCurrent Appointment & Education\n\nName: Byeong-Hak Choe.\nAssistant Professor of Data Analytics and Economics, School of Business at SUNY Geneseo.\nPh.D. in Economics from University of Wyoming.\nM.S. in Economics from Arizona State University.\nM.A. in Economics from SUNY Stony Brook.\nB.A. in Economics & B.S. in Applied Mathematics from Hanyang University at Ansan, South Korea.\n\nMinor in Business Administration.\nConcentration in Finance."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#instructor-2",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#instructor-2",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics, Data Science, and Climate Change\n\nI consider myself an applied economist specializing in environmental economics, with a specific emphasis on climate change.\nMy methodological approach involves leveraging causal inference, econometrics, machine learning methods, and various data science tools for conducting empirical analyses.\nChoe, B.H., 2021. “Social Media Campaigns, Lobbying and Legislation: Evidence from #climatechange/#globalwarming and Energy Lobbies.”\nChoe, B.H. and Ore-Monago, T., 2024. “Governance and Climate Finance in the Developing World”"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-1",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nEmail, Class & Office Hours\n\nEmail: bchoe@geneseo.edu\nClass Homepage:\n\nBrightspace\nGitHub Website\n\nOffice: South Hall 301\nOffice Hours:\n\nTo be determined; By appointment via email."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-2",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-2",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nThis course aims to provide overview of how one can process, clean, and crunch datasets with practical case studies.\nKey topics include:\n\nloading, slicing, filtering, transforming, reshaping, and merging data\nsummarizing and visualizing data,\nexploratory data analysis.\n\nWe will cover these topics to solve real-world data analysis problems with thorough, detailed examples."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-3",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-3",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials\n\nPython for Data Analysis (3rd Edition) by Wes McKinney\nPython Programming for Data Science by Tomas Beuzen\nCoding for Economists by Arthur Turrell\nPython for Econometrics in Economics by Fabian H. C. Raters\nQuantEcon DataScience - Python Fundamentals by Chase Coleman, Spencer Lyon, and Jesse Perla\nQuantEcon DataScience - pandas by Chase Coleman, Spencer Lyon, and Jesse Perla"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-4",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-4",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Requirements\n\nLaptop or personal computer\n\nOperating System: Mac or Windows.\nSpecification: 2+ core CPU, 4+ GB RAM, and 500+ GB disk storage.\n\nHomework: There will be six homework assignments.\nExam: There will be one take-home exam.\nDiscussions: You are encouraged to participate in GitHub-based online discussions.\n\nCheckout the netiquette policy in the syllabus."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-5",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-5",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Schedule and Contents\nThere will be tentatively 7 class sessions."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-6",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#syllabus-6",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAssessments\n\\[\n\\begin{align}\n(\\text{Total Percentage Grade}) =\\quad\\, &0.60\\times(\\text{Total Homework Score})\\notag\\\\\n\\,+\\, &0.30\\times(\\text{Take-Home Exam Score})\\notag\\\\\n\\,+\\, &0.10\\times(\\text{Total Discussion Score})\\notag\n\\end{align}\n\\]\n\nEach of the six homework assignments accounts for 10% of the total percentage grade.\nThe exam account for 30% of the total percentage grade.\nParticipation in discussions accounts for 10% of the total percentage grade."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#why-data-analytics",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#why-data-analytics",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate to prepare my post-graduate career."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#you-at-the-end-of-this-course",
    "title": "Lecture 1",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#why-data-analytics-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#why-data-analytics-1",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts or market analysts.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#why-python-r-and-databases",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#why-python-r-and-databases",
    "title": "Lecture 1",
    "section": "Why Python, R, and Databases?",
    "text": "Why Python, R, and Databases?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#why-python-r-and-databases-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#why-python-r-and-databases-1",
    "title": "Lecture 1",
    "section": "Why Python, R, and Databases?",
    "text": "Why Python, R, and Databases?\n\n\nMost Popular Languagues\n\n\nData Science and Big Data\n\n\n\n\nStack Overflow is the most popular Q & A website specifically for programmers and software developers in the world.\nSee how programming languages have trended over time based on use of their tags in Stack Overflow from 2008 to 2022."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#the-state-of-the-art",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#the-state-of-the-art",
    "title": "Lecture 1",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\n\nData Science and Big Data Trend\nFrom 2008 to 2023\n\n\nProgrammers in 2024"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#the-state-of-the-art-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#the-state-of-the-art-1",
    "title": "Lecture 1",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\nUsers around the world have explored how to best utilize generative pre-trained transformer (GPT) for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI’s capabilities.\n\n\n\n\n\nIf we use Generative AI such as ChatGPT, we should try to understand what Generative AI gives us.\n\nCopying and pasting it without understanding harms our learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-python",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-python",
    "title": "Lecture 1",
    "section": "What is Python?",
    "text": "What is Python?\n\n\nPython is a, simple, easy-to-read, and fast programming language, making it an excellent choice for beginners and experienced developers alike.\n\nVersatility: Python’s extensive library and the vast ecosystem of third-party modules make it suitable for a wide range of applications, from web development and data analysis to machine learning, AI and scientific computing."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-github",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-github",
    "title": "Lecture 1",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code.\nWe will use a GitHub repository to store Python Notebooks.\nCourse contents will be posted not only in Brightspace but also in our GitHub repositories (“repos”) and websites."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-google-colab",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#what-is-google-colab",
    "title": "Lecture 1",
    "section": "What is Google Colab?",
    "text": "What is Google Colab?\n\n\nGoogle Colab is analogous to Google Drive, but specifically for writing and executing Python code in your web browser.\nA key benefit of Colab is that it is entirely free to use and has many of the standard Python modules pre installed.\n\nIt allows for CPU or GPU usage, even for free users, and stores the files in Google’s servers so you can access your files from anywhere you can connect to the Internet.\n\nUsing Colab also means you can entirely avoid the process of installing Python and any dependencies onto your computer.\nColab notebooks don’t just contain Python code. They can contain text, images, and HTML via Markdown!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#how-do-we-use-google-colab-with-github",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#how-do-we-use-google-colab-with-github",
    "title": "Lecture 1",
    "section": "How do we use Google Colab with GitHub?",
    "text": "How do we use Google Colab with GitHub?\n\nHow do we use Google Colab with GitHub?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-1",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-1",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nVariables Are Names, Not Places\n\n\n\n\nA value is datum (literal) such as a number or text.\nThere are different types of values:\n\n352.3 is known as a float or double;\n22 is an integer;\n“Hello World!” is a string."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-2",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-2",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nValues, Variables, and Types\na = 10\nprint(a)\n\n\n\n\n\n\n\nA variable is a name that refers to a value.\n\nWe can think of a variable as a box that has a value, or multiple values, packed inside it.\n\nA variable is just a name!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-3",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-3",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nValues, Variables, and Types\n\n\nSometimes you will hear variables referred to as objects.\nEverything that is not a literal value, such as 10, is an object."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-4",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-4",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nAssignment ( = )\n# Here we assign the integer value 5 to the variable x.\nx = 5   \n\n# Now we can use the variable x in the next line.\ny = x + 12  \ny\n\nIn Python, we use = to assign a value to a variable.\nIn math, = means equality of both sides.\nIn programs, = means assignment: assign the value on the right side to the variable on the left side."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-5",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-5",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nCode and comment style\n\nThe two main principles for coding and managing data are:\n\nMake things easier for your future self.\nDon’t trust your future self.\n\nThe # mark is Google Colab’s comment character.\n\nThe # character has many names: hash, sharp, pound, or octothorpe.\n# indicates that the rest of the line is to be ignored.\nWrite comments before the line that you want the comment to apply to.\n\nConsider adding more comments on code cells and their results using text cells."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-6",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-6",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nAssignment\n\nIn programming code, everything on the right side needs to have a value.\n\nThe right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n\nWhen Python reads y = x + 12, it does the following:\n\nSees the = in the middle.\nKnows that this is an assignment.\nCalculates the right side (gets the value of the object referred to by x and adds it to 12).\nAssigns the result to the left-side variable, y."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-7",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-7",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nVariables Are Names, Not Places\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\ntype(list_example)\n\nThe most basic built-in data types that we’ll need to know about are:\n\nintegers 10\nfloats 1.23\nstrings \"like this\"\nbooleans True\nnothing None\n\nPython also has a built-in type of data container called a list (e.g., [10, 15, 20]) that can contain anything, even different types"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-8",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-8",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nTypes\n\n\n\n\nThe second column (Type) contains the Python name of that type.\nThe third column (Mutable?) indicates whether the value can be changed after creation."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-9",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-9",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBrackets\n\n\nThere are several kinds of brackets in Python, including [], {}, and ().\n\n\n[]{}()\n\n\nvector = ['a', 'b']\nvector[0]\n\n[] is used to denote a list or to signify accessing a position using an index.\n\n\n\n{'a', 'b'}  # set\n{'first_letter': 'a', 'second_letter': 'b'}  # dictionary\n\n{} is used to denote a set or a dictionary (with key-value pairs).\n\n\n\nnum_tup = (1, 2, 3)\nsum(num_tup)\n\n() is used to denote\n\na tuple, or\nthe arguments to a function, e.g., function(x) where x is the input passed to the function."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-10",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-10",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nAll of the basic operators we see in mathematics are available to use:\n\n\n\n\n+ for addition\n- for subtraction\n\n\n\n* for multiplication\n** for powers\n\n\n\n/ for division\n// for integer division\n\n\n\n\nThese work as you’d expect on numbers.\nThese operators are sometimes defined for other built-in data types too.\n\nWe can ‘sum’ strings (which really concatenates them)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-11",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-11",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\nIt works for lists too:\n\n\nstring = \"apples, \"\nprint(string * 3)\n\nWe can multiply strings!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-12",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-12",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\nQ. Classwork 1.1\nUsing Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-13",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-13",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\n10 == 20\n10 == '10'\n\nBoolean data have either True or False value."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-14",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-14",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\n\n\n\n\n\n\n\n\nExisting booleans can be combined, which create a boolean when executed."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-15",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-15",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nConditions are expressions that evaluate as booleans."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-16",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-16",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nboolean_condition1 = 10 == 20\nprint(boolean_condition1)\n\nboolean_condition2 = 10 == '10'\nprint(boolean_condition2)\n\nThe == is an operator that compares the objects on either side and returns True if they have the same values\nQ. What does not (not True) evaluate to?\nQ. Classwork 1.2"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-17",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-17",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nname = \"Geneseo\"\nscore = 99\n\nif name == \"Geneseo\" and score &gt; 90:\n    print(\"Geneseo, you achieved a high score.\")\n\nif name == \"Geneseo\" or score &gt; 90:\n    print(\"You could be called Geneseo or have a high score\")\n\nif name != \"Geneseo\" and score &gt; 90:\n    print(\"You are not called Geneseo and you have a high score\")\n\nThe real power of conditions comes when we start to use them in more complex examples, such as if statements."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-18",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-18",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nOne of the most useful conditional keywords is in.\n\nThis one must pop up ten times a day in most coders’ lives because it can pick out a variable or make sure something is where it’s supposed to be.\n\nQ. Check if “a” is in the string “Sun Devil Arena” using in. Is “a” in “Anyone”?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-19",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-19",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nOne conditional construct we’re bound to use at some point, is the if-else chain:"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-20",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-20",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nCasting Variables\n\n\norig_number = 4.39898498\ntype(orig_number)\n\nmod_number = int(orig_number)\nmod_number\ntype(mod_number)\n\n\n\nSometimes we need to explicitly cast a value from one type to another.\n\nWe can do this using built-in functions like str(), int(), and float().\nIf we try these, Python will do its best to interpret the input and convert it to the output type we’d like and, if they can’t, the code will throw a great big error."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-21",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-21",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nTuples and (im)mutability\n\n\nA tuple is an object that is defined by parentheses and entries that are separated by commas, for example (15, 20, 32). (They are of type tuple.)\nTuples are immutable, while lists are mutable.\nImmutable objects, such as tuples and strings, can’t have their elements changed, appended, extended, or removed.\n\nMutable objects, such as lists, can do all of these things.\n\nIn everyday programming, we use lists and dictionaries more than tuples."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-22",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-22",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nIndentation\n\nWe have seen that certain parts of the code examples are indented.\nCode that is part of a function, a conditional clause, or loop is indented.\nIndention is actually what tells the Python interpreter that some code is to be executed as part of, say, a loop and not to executed after the loop is finished."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-23",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-23",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nIndentation\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nHere’s a basic example of indentation as part of an if statement.\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-24",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-24",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nfor Loops\nname_list = [\"Ben\", \"Chris\", \"Kate\", \"Mary\"]\n\nfor name in name_list:\n    print(name)\n\nA loop is a way of executing a similar piece of code over and over in a similar way.\n\nThe most useful loop is for loops.\n\nAs long as our object is an iterable, then it can be used in this way in a for loop.\nLists, tuples, strings, and dictionaries are iterable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-25",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-25",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nDictionaries\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"Seville\": 36, \"Wellesley\": 29}\n\ncities_to_temps.keys()\ncities_to_temps.values()\ncities_to_temps.items()\n\nAnother built-in Python type that is enormously useful is the dictionary.\n\nThis provides a mapping one set of variables to another (either one-to-one or many-to-one).\nIf you need to create associations between objects, use a dictionary.\n\nWe can obtain keys, values, or key-value paris from dictionaries."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-26",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-26",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nRunning on Empty\n\nBeing able to create empty containers is sometimes useful, especially when using loops.\nThe commands to create empty lists, tuples, dictionaries, and sets are lst = [], tup=(), dic={}, and st = set() respectively.\nQ. What is the type of an empty list?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-27",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-27",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nSlicing Methods\n\n\n\n\nWith slicing methods, we can get subset of the data object.\nSlicing methods can apply for strings, lists, arrays, and DataFrames.\nThe above example describes indexing in Python"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-28",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-28",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nStrings\nstring = \"cheesecake\"\nprint( string[-4:] )\n\nFrom strings, we can access the individual characters via slicing and indexing.\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint( len(string) )\n\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint( len(list_of_numbers) )\n\n\n\nBoth lists and strings will allow us to use the len() command to get their length:"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-29",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-29",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nStrings and Slicing\n\nWe can extract a substring (a part of a string) from a string by using a slice.\nWe define a slice by using square brackets ([]), a start index, an end index, and an optional step count between them.\n\nWe can omit some of these.\n\nThe slice will include characters from index start to one before end:"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-30",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-30",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nGet a Substring with a Slice\n\n[:][ start :][: end ][ start : end ][ start : end : step ]\n\n\nletters = 'abcdefghij'\nletters[:]\n\n[:] extracts the entire sequence from start to end.\n\n\n\nletters = 'abcdefghij'\nletters[4:]\nletters[2:]\nletters[-3:]\nletters[-50:]\n\n[ start :] specifies from the start index to the end.\n\n\n\nletters = 'abcdefghij'\nletters[:3]\nletters[:-3]\nletters[:70]\n\n[: end ] specifies from the beginning to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2:5]\nletters[-26:-24]\nletters[35:37]\n\n[ start : end ] indicates from the start index to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2 : 6 : 2]   # From index 2 to 5, by steps of 2 characters\nletters[ : : 3]     # From the start to the end, in steps of 3 characters\nletters[ 6 : : 4 ]    # From index 19 to the end, by 4\nletters[ : 7 : 5 ]    # From the start to index 6 by 5:\nletters[-1 : : -1 ]   # Starts at the end and ends at the start\nletters[: : -1 ]\n\n[ start : end : step ] extracts from the start index to the end index minus 1, skipping characters by step."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-31",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-31",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\nPython is\n\na zero-indexed language (things start counting from zero);\nleft inclusive;\nright exclusive when we are specifying a range of values."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-32",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-32",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\nlist_example = ['one', 'two', 'three']\nlist_example[ 0 : 1 ]\nlist_example[ 1 : 3 ]\n\n\n\n\nWe can think of items in a list-like object as being fenced in.\n\nThe index represents the fence post."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-33",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-33",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\n[index]slice\n\n\nGet an Item by [index]\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \n\nWe can extract a single value from a list by specifying its index:\n\n\n\nsuny[0]\nsuny[1]\nsuny[2]\nsuny[7]\n\nsuny[-1]\nsuny[-2]\nsuny[-3]\nsuny[-7]\n\n\n\n\nGet an Item with a Slice\n\nWe can extract a subsequence of a list by using a slice:\n\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \nsuny[0:2]    # A slice of a list is also a list.\n\n\nsuny[ : : 2]\nsuny[ : : -2]\nsuny[ : : -1]\n\nsuny[4 : ]\nsuny[-6 : ]\nsuny[-6 : -2]\nsuny[-6 : -4]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-34",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-34",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\nQ. Classwork 1.3"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-35",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-35",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions\nint(\"20\") \nfloat(\"14.3\")\nstr(5)\nint(\"xyz\")\n\nA function can take any number and type of input parameters and return any number and type of output results.\nPython ships with more than 65 built-in functions.\nPython also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-36",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-36",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions, Arguments, and Parameters\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep = \"!\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep=\" \")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that Python passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-37",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-37",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions, Arguments, and Parameters\n\nQ. Classwork 1.4"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-38",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-38",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nImporting Modules, Packages, and Libraries\n\nPython is a general-purpose programming language and is not specialized for numerical or statistical computation.\nThe core libraries that enable Python to store and analyze data efficiently are:\n\npandas\nnumpy\nmatplotlib and seaborn"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-39",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-39",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nImporting Modules, Packages, and Libraries\n\n\npandasnumpymatplotlib and seaborn\n\n\n\n\n\n\npandas provides Series and DataFrames which are used to store data in an easy-to-use format.\n\n\n\n\n\n\n\nnumpy, numerical Python, provides the array block (np.array()) for doing fast and efficient computations;\n\n\n\n\n\n\n\nmatplotlib provides graphics. The most important submodule would be matplotlib.pyplot.\nseaborn provides a general improvement in the default appearance of matplotlib-produced plots."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-40",
    "href": "danl-lec/danl-m1-lec-01-2024-0206.html#python-basics-40",
    "title": "Lecture 1",
    "section": "Python Basics",
    "text": "Python Basics\nImporting Modules, Packages, and Libraries\n\nA module is basically a bunch of related codes saved in a file with the extension .py.\nA package is basically a directory of a collection of modules.\nA library is a collection of packages\nWe refer to code of other modules/pacakges/libraries by using the Python import statement.\n\nThis makes the code and variables in the imported module available to our programming codes.\nWe can use the as keyword when importing the modules using their canonical names.\n\nQ. Classwork 1.5"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-1",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-1",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\n\n\n\nLoading DataFrame\nGetting a Summary of DataFrame\nSelecting Variables in DataFrame\nCounting Values in DataFrame\n\n\n\n\nSorting DataFrame\nIndexing DataFrame\nLocating Observations and Values in DataFrame\nRenaming Variables in DataFrame\nMathematical & Vectorized Operations with DataFrame\nConverting Data Types in DataFrame\nFiltering Observations in DataFrame"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-2",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-2",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet’s read nba.csv as nba.\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\n                  \n# Below is to view the nba DataFrame and to get a summary of it\nnba\nnba.info()\nnba.describe( include=\"all\" )"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-3",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-3",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method’s first parameter, by, accepts the variables that pandas should use to sort the DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-4",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-4",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method’s ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-5",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-5",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-6",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-6",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-7",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-7",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-8",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-8",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-9",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-9",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-10",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-10",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-11",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-11",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-12",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-12",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nHow can we return it to its original form of DataFrame?\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-13",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-13",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nChanging the Order of Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-14",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-14",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-15",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-15",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-16",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-16",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRe-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-17",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-17",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-18",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-18",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n\n\nLet’s consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-19",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-19",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-20",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-20",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-21",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-21",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .iloc[ Index Positions ]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-22",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-22",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 1-4 in Part 1 of Classwork 3!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-23",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-23",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-24",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-24",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-25",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-25",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming columns with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame’s columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-26",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-26",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming columns with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-27",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-27",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-28",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-28",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-29",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-29",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method’s numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-30",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-30",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nVectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-31",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-31",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet’s read employment.csv as emp.\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\n\nWhat values are in the Mgmt variable?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-32",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-32",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series’ values to a different data type.\n\nIt accepts a single argument: the new data type.\nWe can pass either the data type or a string with its name."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-33",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-33",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-34",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-34",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable’s values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-35",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-35",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series’ missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that your choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-36",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-36",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-37",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-37",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\nPandas includes a special data type called a category, - It is ideal for a variable consisting of a small number of unique values relative to its total size. - E.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-38",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-38",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the pd.to_datetime() method\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-39",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-39",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Question 1 in Part 2 of Classwork 3!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-40",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-40",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-41",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-41",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with “Donna”."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-42",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-42",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-43",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-43",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[donnas]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-44",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-44",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nWhat if we want to extract a subset of employees who are not on the “Marketing” team?\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not “Marketing”, and False indicates the Team value is “Marketing”"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-45",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-45",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nWhat if we want to retrieve all the managers in the company? Managers have a value of True in the Mgmt variable.\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-46",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-46",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-47",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-47",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ]\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-48",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-48",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[on_star_teams]\n\nWhat if our next report asked for employees from 15 teams instead of three?\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-49",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-49",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-50",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-50",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ]\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True:"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-51",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-51",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[between_90k_and_100k]\n\nA slightly cleaner solution is to use a method called between()\n\nIt returns a Boolean Series where True denotes that a row’s value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-52",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-52",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[name_starts_with_t]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-53",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-53",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition with the query() method\n# Below two are equivalent\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 and Team == 'Finance'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\nThe query() method is often more readable and more concise, especially for complex conditions, compared to traditional Boolean filtering."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-54",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-54",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 2-6 in Part 2 of Classwork 3!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-55",
    "href": "danl-lec/danl-m1-lec-03-2024-0220.html#pandas-basics-55",
    "title": "Lecture 3",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nReferenes\n\n\nPandas in Action, Boris Paskhaver (Author), 2021, Manning"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-1",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-1",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nAdding and Removing Variables\n\n\nHere we use [] to add variables:\n\nemp['Salary_k'] = emp['Salary'] / 1000\nemp['Salary_2x'] = emp['Salary'] + emp['Salary']\nemp['Salary_3x'] = emp['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-2",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-2",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRemoving Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nemp.drop(columns = \"Salary_k\")\nemp.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-3",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-3",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRelocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = emp.columns.get_loc('Salary') \nvar_to_move = emp.pop('Mgmt')\nemp.insert(ref_var, 'Mgmt', var_to_move) # insert() directly alters 'emp'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‘Reference_Var’)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-4",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-4",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series’ values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-5",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-5",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-6",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-6",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable’s values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-7",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-7",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series’ missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-8",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-8",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-9",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-9",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total size.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-10",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-10",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-11",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-11",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-12",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-12",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Question 1 in Classwork 4!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-13",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-13",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-14",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-14",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with “Donna”.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-15",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-15",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-16",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-16",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-17",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-17",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the “Marketing” team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not “Marketing”, and False indicates the Team value is “Marketing”"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-18",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-18",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-19",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-19",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-20",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-20",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-21",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-21",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-22",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-22",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-23",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-23",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation’s value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-24",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-24",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-25",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-25",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`).\n\nBacktick (`) is the key located next to the number 1 in a keyboard."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-26",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-26",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 2-6 in Classwork 4!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-27",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-27",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-28",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-28",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation’s value is missing.\n\nIs a value of a variable “XYZ” missing?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-29",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-29",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation’s value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-30",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-30",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\",\n                  parse_dates = [\"Start Date\"])\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-31",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-31",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter’s default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-32",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-32",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-33",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-33",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-34",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-34",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-35",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-35",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-36",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-36",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method’s keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-37",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-37",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-38",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-38",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-1",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-1",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\n\nLoading DataFrame\nGetting a Summary of DataFrame\nSelecting Columns in a DataFrame\nCounting Values in a DataFrame\nSorting DataFrame\nIndexing DataFrame"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-2",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-2",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSeries and DataFrame\n\n\n\n\nSeries: a collection of a one-dimensional object containing a sequence of values.\nDataFrame: a collection of Series columns with an index."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-3",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-3",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nImporting a data set with read_csv()\n\n\nA CSV (comma-separated values) is a plain-text file that uses a comma to separate values (e.g., nba.csv).\nThe CSV is widely used for storing data, and we will use this throughout the module.\nWe use the read_csv() function to load a CSV data file.\n\nimport pandas as pd\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")\ntype(nba)\nnba\n\n\nThe DataFrame is the workhorse of the pandas library and the data structure."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-4",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-4",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nImporting a data set with read_csv()\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\nnba\n\nWe can use the parse_dates parameter to coerce the values into datetimes."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-5",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-5",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nColab’s Interactive DataFrame Display\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()  # Enabling an interactive DataFrame display\nnba\n\nWe can use the from keyword when specifying Python package from which we want to import something (e.g., functions).\nColab includes an extension that renders pandas DataFrames into interactive tables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-6",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-6",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDataFrame Terminologies: Variables, Observations, and Values\n\n\n\n\nEach variable is a column.\nEach observation is a row.\nEach value is a cell."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-7",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-7",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDataFrame Terminologies: Dot Operators, Methods and Attributes\n\nThe dot operator (DataFrame.) is used for an attribute or a method on DataFrame.\nA method (DataFrame.METHOD()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\nAn attribute (DataFrame.ATTRIBUTE) is a property that provides information about the DataFrame’s structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-8",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-8",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nGetting a Summary of a DataFrame with .info()\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-9",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-9",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nGetting a Summary of a DataFrame with .describe()\nnba.describe()\nnba.describe(include='all')\n\n.describe() method generates descriptive statistics that summarize the central tendency, dispersion, and distribution of each variable.\n\nIt can also process string-type variables if specified explicitly (include='all')."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-10",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-10",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting a Variable by its Name\nnba_player_name_1 = nba['Name']   # Series\nnba_player_name_1\n\nnba_player_name_2 = nba[ ['Name'] ]   # DataFrame\nnba_player_name_2\n\nIf we want only a specific variable from a DataFrame, we can access the variable with its name using squared brackets, [ ].\n\nDataFrame[ 'var_1' ]\nDataFrame[ ['var_1'] ]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-11",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-11",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting Multiple Variables by their Names\nnba_player_name_team = nba[ ['Name', 'Team'] ]\nnba_player_name_team\n\nIn order to specify multiple variables by their names, we need to pass in a Python list between the square brackets.\n\nDataFrame[ ['var_1', 'var_2', ... ] ]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-12",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-12",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting Multiple Variables with select_dtypes()\n# To include only string variables\nnba.select_dtypes(include = \"object\")\n\n# To exclude string and integer variables\nnba.select_dtypes(exclude = [\"object\", \"int\"])\n\nWe can use the select_dtypes() method to select columns based on their data types.\n\nThe method accepts two parameters, include and exclude."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-13",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-13",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .count()\n\n\nnba['Salary'].count()\nnba[['Salary']].count()\n\n\n\nThe .count() counts the number of non-missing values in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-14",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-14",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .value_counts()\n\n\nnba['Team'].value_counts()\n\nnba[['Team']].value_counts()\n\n\n\nThe .value_counts() counts the number of occurrences of each unique value in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-15",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-15",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .nunique()\n\n\nnba[['Team']].nunique()\n\nnba.nunique()\n\n\n\nThe .nunique() counts the number of unique values in each variable in a DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-16",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-16",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 1-4 in Classwork 2!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-17",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-17",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting the first/last n observations with .head() & .tail()\n\n\nnba.head()\nnba.head(10)\n\nnba.tail()\nnba.tail(10)\n\n\n\nWe can use the .head()/.tail() method of a DataFrame to keep only the first/last n observations.\n\nThis can be useful with sorting methods."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-18",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-18",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\nThe sort_values() method’s first parameter, by, accepts the variables that pandas should use to sort the DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-19",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-19",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\nThe sort_values() method’s ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-20",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-20",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values() and head() & tail()\n\n\ndf = nba.sort_values([\"Salary\"])\ndf.head(5)\n\ndf = nba.sort_values([\"Salary\"])\ndf.tail(5)\n\n\n\nsort_values() with .head() or .tail() can be useful to find the observations with the n smallest/largest values in a variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-21",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-21",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-22",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-22",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-23",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-23",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-24",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-24",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-25",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-25",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each column."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-26",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-26",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-27",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-27",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-28",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-28",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_index()\n\n\n# The two lines below are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True).\n\nnba.sort_index(ascending = False).\n\n\n\nHow can we return it to its original form of DataFrame?\nOur nba DataFrame still has its numeric index.\nIf we could sort the data set by index positions rather than by column values, we could return it to its original shape."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-29",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-29",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nChanging the Order of Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-30",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-30",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-31",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-31",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-32",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-32",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRe-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the chain of method operations\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-33",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-33",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 5-7 in Classwork 2!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-34",
    "href": "danl-lec/danl-m1-lec-02-2024-0213.html#pandas-basics-34",
    "title": "Lecture 2",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nReferenes\n\n\nPandas in Action, Boris Paskhaver (Author), 2021, Manning"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-1",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\n\n\nIn a tidy data.frame,\n\nA variable is in a column.\nAn observation is in a row.\nA value are in a cell.\n\n\nTidy data is a framework to structure data sets so they can be easily analyzed and visualized."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-2",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-2",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\nColumns Contain Values, Not Variables\nData can have columns that contain values instead of variables.\n\nLet’s consider data on income and religion in the United States from the Pew Research Center\n\nimport pandas as pd\npew = pd.read_csv('https://bcdanl.github.io/data/pew.csv')\n\nNot every column here is a variable.\n\nThe values that relate to income are spread across multiple columns.\n\n\nFor data analysis, the pew can be reshaped so that we have religion, income, and count variables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-3",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-3",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\nColumns Contain Values, Not Variables\n## Show only the first few columns\npew.iloc[:,0:5]\nThe form of the data like pew is known as “wide” data. - To turn it into the “long” tidy data format, we will have to melt our DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-4",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-4",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\n\nPandas DataFrames have a method called .melt() that will reshape the DataFrame into a tidy format and it takes a few parameters: - id_vars is a container (list, tuple, ndarray) that represents the variables that will remain as is. - value_vars identifies the columns you want to melt down (or unpivot). - By default, it will melt all the columns not specified in the id_vars parameter. - var_name is a string for the new column name when the value_vars is melted down. - By default, it will be called variable. - value_name is a string for the new column name that represents the values for the var_name. - By default, it will be called value."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-5",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-5",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\nColumns Contain Values, Not Variables\n\n(1)(2)\n\n\n## we do not need to specify a value_vars since we want to pivot\n## all the columns except for the 'religion' column\npew_long = pew.melt(id_vars='religion')\npew_long\n\n## The .melt() method also exists as a pandas function, pd.melt()\n## The below line of code is the equivalent one:\n## melt function\npew_long = pd.melt(pew, id_vars='religion')\n\n\n\nWe can change the defaults so that the melted/unpivoted columns are named.\n\npew_long = pew.melt(\n  id_vars =\"religion\", var_name=\"income\", value_name =\"count\"\n)\n\npew_long"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-6",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-6",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\nKeep Multiple Columns Fixed\n\n(1)(2)\n\n\nNot every data set will have one column to hold still while we unpivot the rest of the columns. - Let’s consider the Billboard data set.\nbillboard = pd.read_csv('https://bcdanl.github.io/data/billboard.csv')\nEach week has its own column. - What if we want to create a faceted plot of the weekly ratings?\n\n\n## use a list to reference more than 1 variable\nbillboard_long = billboard.melt(\n  id_vars = [\"year\", \"artist\", \"track\", \"time\", \"date.entered\"],\n  var_name = \"week\",\n  value_name = \"rating\",\n)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-7",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#tidy-data-7",
    "title": "Lecture 6",
    "section": "Tidy Data",
    "text": "Tidy Data\nColumns Contain Multiple Variables\n\n(1)(2)(3)(4)(5)(6)(2)(3)(4)(5)\n\n\nSometimes columns in a data set may represent multiple variables. - Let’s look at the Ebola data set.\nebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv')\nebola.columns\nebola.iloc[ :5, [0, 1, 2, 10] ]\n\n\nThe column names Cases_Guinea and Deaths_Guinea actually contain two variables. - The individual status (cases and deaths, respectively) as well as the country name, Guinea. - The data is also arranged in a wide format that needs to be reshaped (with the .melt() method). - First, let’s fix the problem by melting the data into long format.\nebola_long = ebola.melt(id_vars=['Date', 'Day'])\n\n\n\nIn this case, we can split the column of interest based on the underscore, _.\n\nWe can use the .split() method that takes a string and “splits” it up based on a given delimiter.\nTo get access to the string methods, we need to use the .str. attribute.\n\n\n## split the column based on a delimiter\nvariable_split = ebola_long.variable.str.split('_')\nvariable_split\ntype(variable_split); type(variable_split[0])\n\n\n\nNow that the column has been split into various pieces, the next step is to assign those pieces to a new column.\n\nTo do so, we can use the .get() string method to “get” the index we want for each row.\n\n\nstatus_values = variable_split.str.get(0)\ncountry_values = variable_split.str.get(1)\n\n\n\nNow that we have the vectors we want, we can add them to our DataFrame.\n\nebola_long['status'] = status_values\nebola_long['country'] = country_values\nebola_long\n\n\n\nIn the .split() method, there is a parameter expand that defaults to False.\n\nWhen we set it to True, it will return a DataFrame where each result of the split is in separate columns. ```{.python} ## reset our ebola_long data ebola_long = ebola.melt(id_vars =[‘Date’, ‘Day’]) ## split the column by _ into a dataframe using expand variable_split = ebola_long.variable.str.split(’_’, expand=True)\n\n\nebola_long[[‘status’, ‘country’]] = variable_split\n\n\n\n::: \n\n\n\n## Tidy Data\n### Variables in Both Rows and Columns \n\n::: {.panel-tabset}\n## (1)\n\nWhat happens if a column of data actually holds two variables instead of one variable?\n  -  In this case, we will have to `pivot` the variable into separate columns, i.e., go from \"long\" data to \"wide\" data.\n\n```{.python}\nweather = pd.read_csv('https://bcdanl.github.io/data/weather.csv')\n\n\nThe weather data include minimum (tmin) and maximum (tmax) temperatures recorded for each day (d1, d2, … , d31) of the month (month). - The element column contains variables that may need to be pivoted wider to become new columns, - The day variables may need to be melted into row values.\nLet’s first fix the day values.\nweather_melt = weather.melt(\n  id_vars=[\"id\", \"year\", \"month\", \"element\"],\n  var_name=\"day\",\n  value_name=\"temp\",\n)\n\n\nNext, we need to pivot up the variables stored in the element column.\nweather_tidy = weather_melt.pivot_table(\n    index = ['id', 'year', 'month', 'day'],\n    columns = 'element',\n    values = 'temp'\n)\n\n\nWe can also flatten the hierarchical columns.\nweather_tidy_flat = weather_tidy.reset_index()\n\n\nFor day variable, we can replace ‘d’ with ““. - Then, convert day from string to integer. - Then, sort weather_tidy_flat by ['year', 'month', 'day'].\nweather_tidy_flat['day'] = weather_tidy_flat.day.str.replace('d', \"\")\nweather_tidy_flat['day'] = weather_tidy_flat['day'].astype(int)\nweather_tidy_flat = weather_tidy_flat.sort_values(by = ['year', 'month', 'day'])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-1",
    "title": "Lecture 6",
    "section": "Data Types",
    "text": "Data Types\nLet’s consider the built-in tips DataFrame from the seaborn library.\nTo get a list of the data types stored in each column of our DataFrame, we call the dtypes attribute.\nimport seaborn as sns\ntips = sns.load_dataset(\"tips\")\ntips.dtypes\n\nThe category data type represents categorical variables.\n\nIt differs from the generic object data type that stores arbitrary Python objects (usually strings)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-2",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-2",
    "title": "Lecture 6",
    "section": "Data Types",
    "text": "Data Types\nConverting Types\n## convert the category sex column into a string dtype\ntips['sex_str'] = tips['sex'].astype(str)\n\n## convert total_bill into a string\ntips['total_bill'] = tips['total_bill'].astype(str)\n\n## convert it back to a float\ntips['total_bill'] = tips['total_bill'].astype(float)\n\n## convert sex into a string\ntips['sex'] = tips['sex'].astype(str)\n\n## convert it back to a category\ntips['sex'] = tips['sex'].astype(category)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-3",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-types-3",
    "title": "Lecture 6",
    "section": "Data Types",
    "text": "Data Types\nto_numeric() method\n\n(1)(2)(3)(4)\n\n\nWhen converting variables into numeric values (e.g., int, float), we can also use the Pandas to_numeric() function. - It handles non-numeric values better.\n\n## subset the tips data\ntips_sub_miss = tips.head(10).copy()\n## assign some 'missing' values\ntips_sub_miss.loc[[1, 3, 5, 7], 'total_bill'] = 'missing'\n\n\n## this will cause an error\ntips_sub_miss['total_bill'].astype(float)\n\n## this will cause an error\npd.to_numeric(tips_sub_miss['total_bill'])\n\n\nThe to_numeric() function has a parameter called errors that governs what happens when the function encounters a value that it is unable to convert to a numeric value. - 'raise': Default. - 'coerce': Invalid parsing will be set as NaN - 'ignore': Invalid parsing will return the input as is.\n\n\ntips_sub_miss[\"total_bill\"] = pd.to_numeric(\n    tips_sub_miss[\"total_bill\"], errors=\"ignore\"\n)\n\ntips_sub_miss[\"total_bill\"]=pd.to_numeric(\n    tips_sub_miss[\"total_bill\"], errors=\"coerce\"\n)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-assembly-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-assembly-1",
    "title": "Lecture 6",
    "section": "Data Assembly",
    "text": "Data Assembly\n\nSometimes, we better combine various DataFrames together to analyze a set of data.\n\nThe data may have been split up into separate DataFrames to reduce the amount of redundant information.\ne.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\nConcatenation can be thought of as appending a row or column to our data. - This approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set. - Let’s consider the following example DataFrames:\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns\ndf1.values"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-1",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\nConcatenating the DataFrames on top of each other uses the concat() function. - All of the DataFrames to be concatenated are passed in a list.\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat\n\nThe row names (i.e., the row indices) are simply a stacked version of the original row indices.\n\nrow_concat.iloc[3, :]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-2",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-2",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\nLet’s consider a new Series and concatenate it with df1:\n\n## create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n## attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-3",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-3",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\nTo fix the problem, we need turn our series into a DataFrame. - This data frame contains one row of data, and the column names are the ones the data will bind to.\nnew_row_df = pd.DataFrame(\n  ## note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-4",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-4",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nIgnore the Index\n\nWe can use the ignore_index parameter to reset the row index after the concatenation if we simply want to concatenate or append data together.\n\nrow_concat_i = pd.concat([df1, df2, df3], ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-5",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-5",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\nConcatenating columns is very similar to concatenating rows. - The main difference is the axis parameter in the concat function. - The default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion. - If we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-6",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-6",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\nAdding a single column to a dataframe can be done directly without using any specific Pandas function.\n\ncol_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']\n\nWe can reset the column indices so we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-7",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-7",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\nWhat would happen when the row and column indices are not aligned?\n\nLet’s modify our DataFrames for the next few examples.\n\n## rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-8",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-8",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-9",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-9",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\nLet’s modify our DataFrames further.\n\n## re-indexing the rows of our dataframes\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-10",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#data-concatenation-10",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data",
    "title": "Lecture 6",
    "section": "Relational data",
    "text": "Relational data\nWhy is one data set sometimes scattered across multiple files? - The size of the files can be huge. - The data collection process can be scattered across time and space.\nSometimes we may have two or more DataFrames (tables) that we want to combine based on common data values. - This task is known in the database world as performing a “join.” - We can do this with the .merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data-1",
    "title": "Lecture 6",
    "section": "Relational data",
    "text": "Relational data\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data-2",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#relational-data-2",
    "title": "Lecture 6",
    "section": "Relational data",
    "text": "Relational data\nMerges\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the “key” variable.\nThe grey column represents the “value” column."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-1",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-1",
    "title": "Lecture 6",
    "section": "Merges",
    "text": "Merges\n\ninnerleftrightouter full\n\n\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n\n\n\n\n\n\n## the default value for 'how' is 'inner'\n## so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')\n\n\n\nA left join keeps all observations in x.\n\n\n\n\n\n\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join.\n\n\n\n\nA right join keeps all observations in y.\n\n\n\n\n\n\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')\n\n\n\nA full join keeps all observations in x and y.\n\n\n\n\n\n\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-2",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-2",
    "title": "Lecture 6",
    "section": "Merges",
    "text": "Merges\nDuplicate keys\n\none-to-manymany-to-many\n\n\n\nOne data frame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3'] })\n\n\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3'] })\none_to_many = x.merge(y, on='key', how='left')\n\n\n\n\n\n\nBoth data frames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_x': ['x1', 'x2', 'x3', 'x4'] })\n\n\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', how='left')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-3",
    "href": "danl-lec/danl-m1-lec-06-2024-0312.html#merges-3",
    "title": "Lecture 6",
    "section": "Merges",
    "text": "Merges\nDefining the key columns\n\nIf the left and right columns do not have the same name for the key columns, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\n\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = x.merge(y, \n                  left_on='key_x', \n                  right_on = 'key_y', \n                  how='left')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-1",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-1",
    "title": "Lecture 7",
    "section": "Missing Data",
    "text": "Missing Data\nRarely will we be given a data set without any missing values.\nPandas usually displays missing values as NaN. - NaN is the actual representation of “Not a Number” values. - I would prefer calling it “Not Available” (NA), for which some other programming languages as well as Pandas use to represent missing values."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-2",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-2",
    "title": "Lecture 7",
    "section": "Missing Data",
    "text": "Missing Data\n\nThe NaN value in Pandas comes from Numpy.\n\nfrom numpy import NaN\nNaN == True\nNaN == 0\nNaN == \"\nNaN == NaN"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-3",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#missing-data-3",
    "title": "Lecture 7",
    "section": "Missing Data",
    "text": "Missing Data\n\nPandas has functions to test for missing values, isnull().\nPandas also has functions for testing non-missing values, notnull().\n\nimport pandas as pd\npd.isnull(NaN)\npd.notnull(NaN)\npd.notnull(210)\npd.notnull('missing')"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from",
    "title": "Lecture 7",
    "section": "Where Can Missing Values Come From?",
    "text": "Where Can Missing Values Come From?\nLoad Data\n\nread_csv()na_valueskeep_default_na\n\n\n\nWhen we load the data, Pandas automatically finds the missing data cell and give us a DataFrame with the NaN value in the appropriate cell.\nIn the read_csv() function, three parameters are related to reading missing values: na_values and keep_default_na.\n\n\n\nThe na_values parameter allows us to specify additional missing or NaN values.\n\nWe can pass in either a Python str (i.e., string) or a list-like object to be automatically coded as missing values when the file is read.\n\npath = 'https://bcdanl.github.io/data/survey_visited.csv'\nsurvey_visited_0 = pd.read_csv(path)\nsurvey_visited_1 = pd.read_csv(path, na_values = [\"MSK-4\"])\n\n\nThe keep_default_na parameter is a bool (i.e., True or False boolean) that allows us to specify whether any additional values need to be considered as missing.\n\nkeep_default_na = False will only use the missing values specified in na_values.\n\nsurvey_visited_2 = pd.read_csv(path, keep_default_na = False)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from-1",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from-1",
    "title": "Lecture 7",
    "section": "Where Can Missing Values Come From?",
    "text": "Where Can Missing Values Come From?\nMerged Data\n\nLet’s merge survey_visited_0 with survey.\n\npath = 'https://bcdanl.github.io/data/survey_survey.csv'\nsurvey = pd.read_csv(path)\nsurvey\n\nvs = survey_visited_0.merge(survey, left_on='ident', right_on='taken')\nvs"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from-2",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#where-can-missing-values-come-from-2",
    "title": "Lecture 7",
    "section": "Where Can Missing Values Come From?",
    "text": "Where Can Missing Values Come From?\nReindexing\n\n(1)(2)\n\n\nAnother way to introduce missing values into our data is to reindex our dataframe.\n\nThis is useful when we want to add new indices to your dataframe, but still want to retain its original values.\nA common usage is when the index represents some time interval, and we want to add more dates.\n\ngapminder = pd.read_csv('https://bcdanl.github.io/data/gapminder.tsv', sep='\\t')\nlife_exp = gapminder.groupby(['year'])['lifeExp'].mean()\n\n\n\nWe can reindex the dataframe by using the .reindex() method.\n\n## subset\ny2000 = life_exp[life_exp.index &gt; 2000]\n\n## reindexing\ny2000.reindex(range(2000, 2010))"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data",
    "title": "Lecture 7",
    "section": "Working With Missing Data",
    "text": "Working With Missing Data\nFind and Count Missing Data\n\n.count()np.count_nonzero().value_counts(dropna=False).sum()\n\n\nOne way to look at the number of missing values is to count() them.\nebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv')\n## count the number of non-missing values\nebola.count()\nQ. Count the number of non-missing values for each variable in ebola.\n\n\nIf we want to count the total number of missing values in our DataFrame, or count the number of missing values for a particular column, we can use the np.count_nonzero() function from numpy in conjunction with the .isnull() method.\nnp.count_nonzero(ebola.isnull())\nnp.count_nonzero(ebola['Cases_Guinea'].isnull())\n\n\nAnother way to get missing data counts is to use the .value_counts() method, giving a frequency table of values in a Series. - If we use the dropna = False, we can also get a missing value count.\ncnts = ebola['Cases_Guinea'].value_counts(dropna=False)\ncnts\n\nThe results are sorted so we can subset the count vector to just look at the missing values.\n\ncnts.loc[pd.isnull(cnts.index)]\n\n\n\nIn Python, True values equate to the integer value 1, and False values equate to the integer value 0.\n\nWe can use this behavior to get the number of missing values by summing up a boolean vector with the .sum() method.\n\n\nebola.Cases_Guinea.isnull().sum()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data-1",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data-1",
    "title": "Lecture 7",
    "section": "Working With Missing Data",
    "text": "Working With Missing Data\nClean Missing Data\n\nCleaning NaN.fillna().fillna(method=‘ffill’).fillna(method=‘bfill’).interpolate().dropna()Calculationskipna\n\n\nThere are many different ways we can deal with missing data. 1. We can replace the missing value with another value, 2. We can fill in the cells with the missing value using existing value, 3. We can drop the observations with missing values from our DataFrame.\n\n\n\nWe can use the .fillna() method to recode the missing values to another value.\n\n## fill the missing values to 0\nebola0 = ebola.fillna(0)\n\n\n\nWe can use built-in methods to fill forward (method = ffill).\n\nWhen we fill data forward, the last known value (from top to bottom) is used for the next missing value.\n\n\nebola_f = ebola.fillna(method='ffill')\n\n\n\nWe can also use built-in methods to fill backward (method = bfill).\n\nWhen we fill data backward, the newest value (from top to bottom) is used to replace the missing data.\n\n\nebola_b = ebola.fillna(method='bfill')\n\n\n\nInterpolation uses existing values to fill in missing values.\n\nBy default, .interpolate() treats the missing values as if they should be equally spaced apart.\n\nebola_linear = ebola.interpolate()\nThe .interpolate() method behaves kind of in a forward fill fashion.\n\n\n\nIf we want to keep the observations with only non-missing values, we can use .dropna()\nebola_dropna = ebola.dropna()\nWe are left with just one row of data!\n\n\nSuppose we wanted to look at the case counts for multiple regions.\n\n\nebola[\"Cases_multiple\"] = (\n  ebola[\"Cases_Guinea\"]\n  + ebola[\"Cases_Liberia\"]\n  + ebola[\"Cases_SierraLeone\"]\n)\n\nebola_subset = ebola.loc[:,\n    [\"Cases_Guinea\", \n     \"Cases_Liberia\", \n     \"Cases_SierraLeone\",\n     \"Cases_multiple\"] ]\n\n\n\n\n.mean() and .sum() can ignore missing values. - These functions will typically have a skipna parameter that will still calculate a value by skipping over the missing values.\nebola.Cases_Guinea.sum(skipna = True) ## default\nebola.Cases_Guinea.sum(skipna = False)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data-2",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#working-with-missing-data-2",
    "title": "Lecture 7",
    "section": "Working With Missing Data",
    "text": "Working With Missing Data\nPandas Built-In NA Missing\nPandas 1.0 introduced a built-in &lt;NA&gt; value (pd.NA).\n\neconomists = pd.DataFrame(\n  {\n    \"Name\": [\"John Forbes Nash\", \"William Nordhaus\"],\n    \"Occupation\": [\"Mathematician\", \"Climate Economist\"],\n    \"Born\": [\"1928-06-13\", \"1941-05-31\"],\n    \"Died\": [\"2015-05-23\", \"\"],\n    \"Age\": [86, 81]\n  }\n)\n\neconomists.loc[1, \"Age\"] = pd.NA"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times",
    "title": "Lecture 7",
    "section": "Dates and Times",
    "text": "Dates and Times\nPython’s datetime Object\nOne of the bigger reasons for using Pandas is its ability to work with timeseries data.\n\nWe can use datetime to get the current date and time.\n\nfrom datetime import datetime\nnow = datetime.now()\n\nWe can also create our own datetime manually.\n\n\nt1 = datetime.now()\nt2 = datetime(2000,1,1)\n\ndiff = t1 - t2\ntype(diff)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-1",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-1",
    "title": "Lecture 7",
    "section": "Dates and Times",
    "text": "Dates and Times\nConverting to datetime\n\ndata.to_datatime()formatparse_dates\n\n\n\nLet’s load up our Ebola data set and convert the Date column into a proper datetime object.\n\nimport pandas as pd\nebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv')\nebola.info()\n\nThe Date column is encoded as a generic string object.\n\n\n\n\nWe can use .to_datatime() to create a new column, date_dt, that converts the Date column into a datetime.\n\nebola['date_dt'] = pd.to_datetime(ebola['Date'])\n\n\n\nThe to_datetime() method has a parameter called format that allows us to manually specify the format of the date.\n\n\n\nThe read_csv() function has several parameters about datetime. - We can parse the Date column directly by specifying the column we want in the parse_dates parameter.\nebola = pd.read_csv('https://bcdanl.github.io/data/country_timeseries.csv', parse_dates=[\"Date\"])"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-2",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-2",
    "title": "Lecture 7",
    "section": "Dates and Times",
    "text": "Dates and Times\nExtracting Date Components\nNow that we have a datetime object, we can extract various parts of the date, such as year, month, or day.\nLet’s consider the example datetime object.\nd = pd.to_datetime('2021-12-14')\ntype(d)\nd.year\nd.month\nd.day\nd.quarter"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-3",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-3",
    "title": "Lecture 7",
    "section": "Dates and Times",
    "text": "Dates and Times\nExtracting Date Components in DataFrame\n\nWe can extract various parts of the datetime column in DataFrame by accessing datetime methods using the .dt accessor.\n\nebola['date_dt'] = pd.to_datetime(ebola['Date'])\n\nebola = ebola.assign(\n    year = ebola[\"date_dt\"].dt.year,\n    month = ebola[\"date_dt\"].dt.month,\n    day = ebola[\"date_dt\"].dt.day\n)\n\nebola.info() ## what are the data types of year, month, and day?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-4",
    "href": "danl-lec/danl-m1-lec-07-2024-0319.html#dates-and-times-4",
    "title": "Lecture 7",
    "section": "Dates and Times",
    "text": "Dates and Times\nDate Ranges\n\n(1)(2)(3)\n\n\n\nIn our Ebola data set, we do not have an observation for every day in the date range.\n\nThis is quite common.\n\n\nebola = pd.read_csv(\n'https://bcdanl.github.io/data/country_timeseries.csv', parse_dates=[\"Date\"]\n)\n\nHere, 2015-01-01 is missing.\n\n\n\n\nIt’s common practice to create a date range to .reindex() a data set.\n\nWe can use the date_range().\n\n\nhead_range = pd.date_range(start='2014-12-31', end='2015-01-05')\nebola_5 = ebola.head()\nebola_5.index = ebola_5['Date']\nebola_5 = ebola_5.reindex(head_range)\n\n\nebola = pd.read_csv(\n  \"https://bcdanl.github.io/data/country_timeseries.csv\",\n  index_col=\"Date\",\n  parse_dates=[\"Date\"],\n)\n\nnew_idx = pd.date_range(ebola.index.min(), ebola.index.max())\nnew_idx = reversed(new_idx) ## to reverse new_idx\nebola = ebola.reindex(new_idx)"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html",
    "href": "danl-cw/danl-m1-cw-5.html",
    "title": "Classwork 5",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#load-libraries",
    "href": "danl-cw/danl-m1-cw-5.html#load-libraries",
    "title": "Classwork 5",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#load-dataframe",
    "href": "danl-cw/danl-m1-cw-5.html#load-dataframe",
    "title": "Classwork 5",
    "section": "Load DataFrame",
    "text": "Load DataFrame\n\nbillboard = pd.read_csv('https://bcdanl.github.io/data/billboard.csv')\nny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')\ncovid = pd.read_csv('https://bcdanl.github.io/data/covid19_cases.csv')"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q1a",
    "href": "danl-cw/danl-m1-cw-5.html#q1a",
    "title": "Classwork 5",
    "section": "Q1a",
    "text": "Q1a\n\nDescribe how the distribution of rating varies across week 1, week 2, and week 3 using the faceted histogram. \n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q1b",
    "href": "danl-cw/danl-m1-cw-5.html#q1b",
    "title": "Classwork 5",
    "section": "Q1b",
    "text": "Q1b\n\nWhich artist(s) have the most number of tracks in billboard DataFrame? \n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q1c",
    "href": "danl-cw/danl-m1-cw-5.html#q1c",
    "title": "Classwork 5",
    "section": "Q1c",
    "text": "Q1c\n\nMake ny_pincp longer.\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q1d",
    "href": "danl-cw/danl-m1-cw-5.html#q1d",
    "title": "Classwork 5",
    "section": "Q1d",
    "text": "Q1d\n\nMake a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q1e",
    "href": "danl-cw/danl-m1-cw-5.html#q1e",
    "title": "Classwork 5",
    "section": "Q1e",
    "text": "Q1e\n\nUse the wide-form DataFrame of covid to find the top 10 countries for which their cases are highly correlated with USA’s cases using DataFrame.corr()\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#load-dataframe-for-q2a-and-q2b",
    "href": "danl-cw/danl-m1-cw-5.html#load-dataframe-for-q2a-and-q2b",
    "title": "Classwork 5",
    "section": "Load DataFrame for Q2a and Q2b",
    "text": "Load DataFrame for Q2a and Q2b\n\npaidsearch = pd.read_csv('https://bcdanl.github.io/data/paidsearch.csv')\n\n\nVariable description\n\ndma: an identification number of a designated market (DM) area i (e.g., Boston, Los Angeles)\ntreatment_period: 0 if date is before May 22, 2012 and 1 after.\nsearch_stays_on: 1 if the paid-search goes off in dma i, 0 otherwise.\nrevenue: eBay’s sales revenue for dma i and date t"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q2a",
    "href": "danl-cw/danl-m1-cw-5.html#q2a",
    "title": "Classwork 5",
    "section": "Q2a",
    "text": "Q2a\nSummarize the mean vale of revenue for each group of search_stays_on and for each date.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q2b",
    "href": "danl-cw/danl-m1-cw-5.html#q2b",
    "title": "Classwork 5",
    "section": "Q2b",
    "text": "Q2b\nCalculate the log difference between mean revenues in each group of search_stays_on. (This is the log of the average revenue in group of search_stays_on == 1 minus the log of the average revenue in group of search_stays_on == 0.)\n\nFor example, consider the following two observations:\nThe log difference of daily mean revenues between the two group of search_stays_on for date 1-Apr-12 is log(120277.57) - log(93650.68).\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#load-dataframe-for-q2c-q2d-and-q2e",
    "href": "danl-cw/danl-m1-cw-5.html#load-dataframe-for-q2c-q2d-and-q2e",
    "title": "Classwork 5",
    "section": "Load DataFrame for Q2c, Q2d, and Q2e",
    "text": "Load DataFrame for Q2c, Q2d, and Q2e\n\npaid_search = pd.read_csv('https://bcdanl.github.io/data/paid_search.csv')"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q2c",
    "href": "danl-cw/danl-m1-cw-5.html#q2c",
    "title": "Classwork 5",
    "section": "Q2C",
    "text": "Q2C\nSort paid_search by DM and May22_2012 in ascending order.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q2d",
    "href": "danl-cw/danl-m1-cw-5.html#q2d",
    "title": "Classwork 5",
    "section": "Q2d",
    "text": "Q2d\nFor each DM, calculate the difference between log_revenue before and after May22_2012.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#q2e",
    "href": "danl-cw/danl-m1-cw-5.html#q2e",
    "title": "Classwork 5",
    "section": "Q2e",
    "text": "Q2e\n\nConsider the DataFrame from Q2d.\nFor each group of no_paid_search, calculate the mean value of the difference between log_revenue before and after May22_2012 .\nWhat is the difference in the mean values?\nAfter the paid-search went off, sales revenue decreased by 0.66%\n\nWas eBay’s paid search worth it?\n\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html",
    "href": "danl-cw/danl-m1-cw-6.html",
    "title": "Classwork 6",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#load-libraries",
    "href": "danl-cw/danl-m1-cw-6.html#load-libraries",
    "title": "Classwork 6",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q1a",
    "href": "danl-cw/danl-m1-cw-6.html#q1a",
    "title": "Classwork 6",
    "section": "Q1a",
    "text": "Q1a\nWrite a Pandas code to join the two given DataFrames along rows and assign all data.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q1b",
    "href": "danl-cw/danl-m1-cw-6.html#q1b",
    "title": "Classwork 6",
    "section": "Q1b",
    "text": "Q1b\nWrite a Pandas code to join the two given DataFrames along columns and assign all data.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q1c",
    "href": "danl-cw/danl-m1-cw-6.html#q1c",
    "title": "Classwork 6",
    "section": "Q1c",
    "text": "Q1c\nConsider the following Pandas Series\nWrite a Pandas code to append rows to DataFrame student_data1 and display the combined data using DATAFRAME.append(SERIES, ignore_index = True)\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q2a",
    "href": "danl-cw/danl-m1-cw-6.html#q2a",
    "title": "Classwork 6",
    "section": "Q2a",
    "text": "Q2a\nMerge flights with weather.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q2b",
    "href": "danl-cw/danl-m1-cw-6.html#q2b",
    "title": "Classwork 6",
    "section": "Q2b",
    "text": "Q2b\nFind the airline that has the longest positive dep_delay on average.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-6.html#q2c",
    "href": "danl-cw/danl-m1-cw-6.html#q2c",
    "title": "Classwork 6",
    "section": "Q2c",
    "text": "Q2c\nFind the airline that has the largest proportion of flights with longer than 30-minute dep_delay.\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html",
    "href": "danl-cw/danl-m1-cw-3.html",
    "title": "Classwork 3",
    "section": "",
    "text": "The nfl.csv file (with its pathname https://bcdanl.github.io/data/nfl.csv) contains a list of players in the National Football League with similar Name, Team, Position, Birthday, and Salary variables in the nba.csv file we used in class.\n\nimport pandas as pd\n\n\n\n\n\n\n\n\n\n\n\n\n\nWho are the five highest-paid players?\nWho is the oldest player?\n\nAnswer:\n\n\n\n\nHow can we sort the DataFrame first by Team in alphabetical order and then by Salary in descending order?\nAnswer:\n\n\n\n\nHow can we set the DataFrame index to store the player names?\nAnswer:\n\n\n\n\nWho is the oldest player on the Kansas City Chiefs roster, and what is his birthday?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html#direction",
    "href": "danl-cw/danl-m1-cw-3.html#direction",
    "title": "Classwork 3",
    "section": "",
    "text": "The nfl.csv file (with its pathname https://bcdanl.github.io/data/nfl.csv) contains a list of players in the National Football League with similar Name, Team, Position, Birthday, and Salary variables in the nba.csv file we used in class.\n\nimport pandas as pd"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html#question-1",
    "href": "danl-cw/danl-m1-cw-3.html#question-1",
    "title": "Classwork 3",
    "section": "",
    "text": "Who are the five highest-paid players?\nWho is the oldest player?\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html#question-2",
    "href": "danl-cw/danl-m1-cw-3.html#question-2",
    "title": "Classwork 3",
    "section": "",
    "text": "How can we sort the DataFrame first by Team in alphabetical order and then by Salary in descending order?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html#question-3",
    "href": "danl-cw/danl-m1-cw-3.html#question-3",
    "title": "Classwork 3",
    "section": "",
    "text": "How can we set the DataFrame index to store the player names?\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-3.html#question-4",
    "href": "danl-cw/danl-m1-cw-3.html#question-4",
    "title": "Classwork 3",
    "section": "",
    "text": "Who is the oldest player on the Kansas City Chiefs roster, and what is his birthday?\nAnswer:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANL Module 1: Data Preparation and Management, 2024",
    "section": "",
    "text": "Welcome! 👋\n\\(-\\) Explore, Learn, and Grow with the DANL Microcredential! 🌟"
  },
  {
    "objectID": "index.html#bullet-lecture-slides",
    "href": "index.html#bullet-lecture-slides",
    "title": "DANL Module 1: Data Preparation and Management, 2024",
    "section": "\\(\\bullet\\,\\) Lecture Slides 🚀",
    "text": "\\(\\bullet\\,\\) Lecture Slides 🚀\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nFebruary 6, 2024\n\n\n\n\nLecture 2\n\n\nFebruary 13, 2024\n\n\n\n\nLecture 3\n\n\nFebruary 20, 2024\n\n\n\n\nLecture 4\n\n\nFebruary 27, 2024\n\n\n\n\nLecture 5\n\n\nMarch 5, 2024\n\n\n\n\nLecture 6\n\n\nMarch 12, 2024\n\n\n\n\nLecture 7\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-classwork",
    "href": "index.html#bullet-classwork",
    "title": "DANL Module 1: Data Preparation and Management, 2024",
    "section": "\\(\\bullet\\,\\) Classwork ⌨️",
    "text": "\\(\\bullet\\,\\) Classwork ⌨️\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nFebruary 6, 2024\n\n\n\n\nClasswork 2\n\n\nFebruary 13, 2024\n\n\n\n\nClasswork 3\n\n\nFebruary 20, 2024\n\n\n\n\nClasswork 4\n\n\nFebruary 27, 2024\n\n\n\n\nClasswork 5\n\n\nMarch 5, 2024\n\n\n\n\nClasswork 6\n\n\nMarch 12, 2024\n\n\n\n\nClasswork 7\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-weekly-q-a",
    "href": "index.html#bullet-weekly-q-a",
    "title": "DANL Module 1: Data Preparation and Management, 2024",
    "section": "\\(\\bullet\\,\\) Weekly Q & A ❓",
    "text": "\\(\\bullet\\,\\) Weekly Q & A ❓\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1 - Q & A\n\n\nFebruary 6, 2024\n\n\n\n\nWeek 2 - Q & A\n\n\nFebruary 13, 2024\n\n\n\n\nWeek 3 - Q & A\n\n\nFebruary 20, 2024\n\n\n\n\nWeek 4 - Q & A\n\n\nFebruary 27, 2024\n\n\n\n\nWeek 5 - Q & A\n\n\nMarch 5, 2024\n\n\n\n\nWeek 6 - Q & A\n\n\nMarch 12, 2024\n\n\n\n\nWeek 7 - Q & A\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-homework",
    "href": "index.html#bullet-homework",
    "title": "DANL Module 1: Data Preparation and Management, 2024",
    "section": "\\(\\bullet\\,\\) Homework 💻",
    "text": "\\(\\bullet\\,\\) Homework 💻\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nFebruary 6, 2024\n\n\n\n\nHomework 2\n\n\nFebruary 13, 2024\n\n\n\n\nHomework 3\n\n\nFebruary 20, 2024\n\n\n\n\nHomework 4\n\n\nFebruary 27, 2024\n\n\n\n\nHomework 5\n\n\nMarch 5, 2024\n\n\n\n\nHomework 6\n\n\nMarch 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-06.html",
    "href": "danl-qa/danl-m1-qa-06.html",
    "title": "Week 6 - Q & A",
    "section": "",
    "text": "Welcome to our Week 6 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 6, including Lecture 6 slides, Classwork 6, and Homework Assignment 6.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 6 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-05.html",
    "href": "danl-qa/danl-m1-qa-05.html",
    "title": "Week 5 - Q & A",
    "section": "",
    "text": "Welcome to our Week 1 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 5, including Lecture 5 slides, Classwork 5, and Homework Assignment 5.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 5 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-qa/danl-m1-qa-02.html",
    "href": "danl-qa/danl-m1-qa-02.html",
    "title": "Week 2 - Q & A",
    "section": "",
    "text": "Welcome to our Week 2 Discussion Board! 👋 \nThis space is designed for you to engage with your classmates about the material covered in Week 2, including Lecture 2 slides, Classwork 2, and Homework Assignment 2.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Week 2 materials or need clarification on any points, don’t hesitate to ask here.\nLet’s collaborate and learn from each other!\n\n\n\n Back to top"
  },
  {
    "objectID": "listing-danl-m1-cw.html",
    "href": "listing-danl-m1-cw.html",
    "title": "DANL Module 1 - Classwork",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nPython Basics\n\n\nFebruary 6, 2024\n\n\n\n\nClasswork 2\n\n\nPandas Basics - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\n\n\nFebruary 13, 2024\n\n\n\n\nClasswork 3\n\n\nPandas Basics - Sorting and Indexing Data\n\n\nFebruary 20, 2024\n\n\n\n\nClasswork 4\n\n\nConvering Data Types; Filtering Data; Dealing with Missing Values/Duplicates\n\n\nFebruary 27, 2024\n\n\n\n\nClasswork 5\n\n\nDealing with Missing Values/Duplicates\n\n\nMarch 5, 2024\n\n\n\n\nClasswork 6\n\n\nMerging, Joining, and Concaternating DataFrames [Classwork 6 may be subject to change during the Module.]\n\n\nMarch 12, 2024\n\n\n\n\nClasswork 7\n\n\nMissing Data; Time-series Data [Classwork 7 may be subject to change during the Module.]\n\n\nMarch 19, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html",
    "href": "danl-hw/danl-m1-hw-5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Homework 5 to the Brightspace with the name below:\n\ndanl-m1-hw5-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m1-hw5-choe-byeonghak.ipynb )\n\nThe due is March 12, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nPlease prepare a Jupyter/Python Notebook (*.ipynb) to address all questions.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question.\n\n\nImport the pandas library, and read fao_stat.csv as fao:\n\nimport pandas as pd\n\nfao = pd.read_csv(\"https://bcdanl.github.io/data/fao_stat.csv\",\n                  encoding = 'ISO-8859-1')\n\n\n\n\n\n\nThe fao DataFrame contains the country-year level observation regarding variables below:\n\nSSA: A boolean indicating if the country is in Sub-Saharan Africa.\nArea: The name of the country.\nYear: The year of observation.\ngdp_per_capita: GDP per capita.\ndrinking_water: The percentage of the population with access to safe drinking water.\nsanitation_service: The percentage of the population with access to improved sanitation services.\nchildren_stunted: The percentage of children under 5 years old who are stunted.\nchildren_overweight: The percentage of children under 5 years old who are overweight.\ninvestment_pct: The percentage of GDP invested in public health.\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\nWhat percentage of the values is missing for each variable?\nAnswer\n\n\n\n\n\nFill missing values in the gdp_per_capita variable with the mean value of that variable.\nAnswer\n\n\n\n\nDrop observations where drinking_water or sanitation_service information is missing.\nAnswer\n\n\n\n\nWhat is the average drinking_water access percentage for each Area grouped by SSA status?\nAnswer\n\n\n\n\nCalculate the mean sanitation_service percentage for each combination of SSA status and Year.\nHint: We can group a DataFrame by a list of multiple variables. Then, each group corresponds to a unique combination of values across the specified variables.\nAnswer\n\n\n\n\nFor each year, find the 5 worst countries in terms of drinking_water.\n\nHint: We can start with the sort_values() method.\nNote: DataFrameGroupBy does not support the sort_values() method.\n\nAnswer\n\n\n\n\nFor each year, find the 5 worst countries in terms of children_stunted.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-6.html",
    "href": "danl-hw/danl-m1-hw-6.html",
    "title": "Homework 6",
    "section": "",
    "text": "Direction\n\nWrite a Python code to answer each question.\nMake at least some simple comment (# ...) in each question.\nImport Python libraries you need here.\n\n\nCiti Bike NYC is New York City’s official bike-sharing program. Residents and tourists can pick up and drop off bicycles at hundreds of locations around the city. Ride data is publicly available and released monthly by the city at https://www.citibikenyc.com/system-data. citibike.csv is a collection of ~1.9 million rides that cyclists took in June 2020. For simplicity’s sake, the data set has been modified from its original version and includes only two columns: each ride’s start time and end time. Let’s import the data set and assign it to a citi_bike variable:\n\nciti_bike = pd.read_csv(\"citibike.csv\")\n\n\n\nQuestion 1\nConvert the start_time and stop_time columns to store datetime (Timestamp) values instead of strings.\n\n\n\nQuestion 2\nCount the rides that occurred on each day of the week (Monday, Tuesday, and so on). Which weekday is the most popular for a bike ride? Use the start_time column as your starting point.\n\n\n\nQuestion 3\nCount the rides per week for each week within the month. To do so, round each date in the start_time column to its previous or current Monday. Assume that each week starts on a Monday and ends on a Sunday. Thus, the first week of June would be Monday, June 1 through Sunday, June 7.\n\n\n\nQuestion 4\nCalculate the duration of each ride, and save the results to a new duration column.\n\n\n\nQuestion 5\nFind the average duration of a bike ride.\n\n\n\nQuestion 6\nExtract the five longest bike rides by duration from the data set.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html",
    "href": "danl-hw/danl-m1-hw-3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Homework 3 to the Brightspace with the name below:\n\ndanl-m1-hw3-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m1-hw3-choe-byeonghak.ipynb )\n\nThe due is February 27, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nPlease prepare a Jupyter/Python Notebook (*.ipynb) to address all questions.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#variable-description",
    "href": "danl-hw/danl-m1-hw-3.html#variable-description",
    "title": "Homework 3",
    "section": "Variable Description",
    "text": "Variable Description\n\nFiscal Year: Fiscal Year;\nPayroll Number: Payroll Number;\nAgency Name: The Payroll agency that the employee works for;\nLast Name: Last name of employee;\nFirst Name: First name of employee;\nMid Init: Middle initial of employee;\nAgency Start Date: Date which employee began working for their current agency;\nWork Location Borough: Borough of employee’s primary work location;\nTitle Description: Civil service title description of the employee;\nLeave Status as of June 30: Status of employee as of the close of the relevant fiscal year;\nBase Salary: Base Salary assigned to the employee;\nPay Basis: Lists whether the employee is paid on an hourly, per diem or annual basis;\nRegular Hours: Number of regular hours employee worked in the fiscal year;\nRegular Gross Paid: The amount paid to the employee for base salary during the fiscal year;\nOT Hours: Overtime Hours worked by employee in the fiscal year;\nTotal OT Paid: Total overtime pay paid to the employee in the fiscal year;\nTotal Other Pay: Includes any compensation in addition to gross salary and overtime pay, ie Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-1",
    "href": "danl-hw/danl-m1-hw-3.html#question-1",
    "title": "Homework 3",
    "section": "Question 1",
    "text": "Question 1\nSelect “First Name”, “Last Name”, “Base Salary”, and “Total OT Paid”, then sort these selected variables by “Base Salary” in descending order and display the top 10 entries.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-2",
    "href": "danl-hw/danl-m1-hw-3.html#question-2",
    "title": "Homework 3",
    "section": "Question 2",
    "text": "Question 2\nCreate a new DataFrame that includes employees from the “DEPARTMENT OF EDUCATION ADMIN” agency where the variables are “First Name”, “Last Name”, “Title Description”, “Base Salary”, and “Total OT Paid”. Additionally, include a new variable “Total Compensation” which is the sum of “Base Salary” and “Total OT Paid”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-3",
    "href": "danl-hw/danl-m1-hw-3.html#question-3",
    "title": "Homework 3",
    "section": "Question 3",
    "text": "Question 3\nUsing set_index(), change the DataFrame’s index to “Last Name”, then locate the data for a specific last name, say “BROWN”, and display their “Agency Name”, “Base Salary”, and “Total OT Paid”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-4",
    "href": "danl-hw/danl-m1-hw-3.html#question-4",
    "title": "Homework 3",
    "section": "Question 4",
    "text": "Question 4\nFind the 5 employees with the highest “Regular Gross Paid” and calculate their average “OT Hours”. Also, reset the index if you have changed it previously.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-5",
    "href": "danl-hw/danl-m1-hw-3.html#question-5",
    "title": "Homework 3",
    "section": "Question 5",
    "text": "Question 5\nSort the DataFrame by “Fiscal Year” and “Total Other Pay” in descending order, then set “First Name” as the index and use the loc accessor to retrieve the “Total Other Pay” for a specific first name, say “MICHAEL”.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-6",
    "href": "danl-hw/danl-m1-hw-3.html#question-6",
    "title": "Homework 3",
    "section": "Question 6",
    "text": "Question 6\n\nSelect employees who have “OT Hours” greater than 0, calculate their “OT Rate” (Total OT Paid / OT Hours), and then find the employee with the highest “OT Rate”. Display their full name and OT Rate.\n\nHint: Start with filtering observations in nyc_payroll with the following lines:\n\n\n\n# Boolean Series of whether or not 'OT Hours' is greater than 0.\npos_OT_hours = nyc_payroll['OT Hours'] &gt; 0 \n\n# Keeping only the observations with pos_OT_hours == True\nwith_ot = nyc_payroll[ pos_OT_hours ] \n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-3.html#question-7",
    "href": "danl-hw/danl-m1-hw-3.html#question-7",
    "title": "Homework 3",
    "section": "Question 7",
    "text": "Question 7\nSort the DataFrame first by “Work Location Borough” alphabetically, and then by “Total Compensation” (sum of “Base Salary” and “Total OT Paid”) in descending order within each borough.\nAnswer"
  },
  {
    "objectID": "listing-danl-m1-hw.html",
    "href": "listing-danl-m1-hw.html",
    "title": "DANL Module 1 - Homework",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nPython Basics\n\n\nFebruary 6, 2024\n\n\n\n\nHomework 2\n\n\nPandas Basics - Loading, Summarizing, Selecting, Counting, and Sorting Data\n\n\nFebruary 13, 2024\n\n\n\n\nHomework 3\n\n\nPandas Basics - Sorting, Indexing, and Locating Data\n\n\nFebruary 20, 2024\n\n\n\n\nHomework 4\n\n\nPandas Basics - Sorting and Filtering Data\n\n\nFebruary 27, 2024\n\n\n\n\nHomework 5\n\n\nDealing with Missing Values; Group Operations\n\n\nMarch 5, 2024\n\n\n\n\nHomework 6\n\n\nMerging, Joining, and Concaternating DataFrames [Homework 6 may be subject to change during the Module.]\n\n\nMarch 12, 2024\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-39",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-39",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation’s uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-40",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-40",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-41",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-41",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value’s last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of “Douglas” and a Gender of “Male”. Then check which “Douglas” is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-42",
    "href": "danl-lec/danl-m1-lec-04-2024-0227.html#pandas-basics-42",
    "title": "Lecture 4",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 7-8 in Classwork 4!"
  },
  {
    "objectID": "danl-m1-hw-3-a.html",
    "href": "danl-m1-hw-3-a.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Homework 3 to the Brightspace with the name below:\n\ndanl-m1-hw3-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-m1-hw3-choe-byeonghak.ipynb )\n\nThe due is February 27, 2024, 7:00 P.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions.\nPlease prepare a Jupyter/Python Notebook (*.ipynb) to address all questions.\nMake at least some simple comment (# ...) in each question.\nMake one text cell to explain things in each question."
  },
  {
    "objectID": "danl-m1-hw-3-a.html#variable-description",
    "href": "danl-m1-hw-3-a.html#variable-description",
    "title": "Homework 3",
    "section": "Variable Description",
    "text": "Variable Description\n\nFiscal Year: Fiscal Year;\nPayroll Number: Payroll Number;\nAgency Name: The Payroll agency that the employee works for;\nLast Name: Last name of employee;\nFirst Name: First name of employee;\nMid Init: Middle initial of employee;\nAgency Start Date: Date which employee began working for their current agency;\nWork Location Borough: Borough of employee’s primary work location;\nTitle Description: Civil service title description of the employee;\nLeave Status as of June 30: Status of employee as of the close of the relevant fiscal year;\nBase Salary: Base Salary assigned to the employee;\nPay Basis: Lists whether the employee is paid on an hourly, per diem or annual basis;\nRegular Hours: Number of regular hours employee worked in the fiscal year;\nRegular Gross Paid: The amount paid to the employee for base salary during the fiscal year;\nOT Hours: Overtime Hours worked by employee in the fiscal year;\nTotal OT Paid: Total overtime pay paid to the employee in the fiscal year;\nTotal Other Pay: Includes any compensation in addition to gross salary and overtime pay, ie Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-1",
    "href": "danl-m1-hw-3-a.html#question-1",
    "title": "Homework 3",
    "section": "Question 1",
    "text": "Question 1\nSelect “First Name”, “Last Name”, “Base Salary”, and “Total OT Paid”, then sort these selected variables by “Base Salary” in descending order and display the top 10 entries.\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-2",
    "href": "danl-m1-hw-3-a.html#question-2",
    "title": "Homework 3",
    "section": "Question 2",
    "text": "Question 2\nCreate a new DataFrame that includes employees from the “DEPARTMENT OF EDUCATION ADMIN” agency where the variables are “First Name”, “Last Name”, “Title Description”, “Base Salary”, and “Total OT Paid”. Additionally, include a new variable “Total Compensation” which is the sum of “Base Salary” and “Total OT Paid”.\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-3",
    "href": "danl-m1-hw-3-a.html#question-3",
    "title": "Homework 3",
    "section": "Question 3",
    "text": "Question 3\nUsing set_index(), change the DataFrame’s index to “Last Name”, then locate the data for a specific last name, say “BROWN”, and display their “Agency Name”, “Base Salary”, and “Total OT Paid”.\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-4",
    "href": "danl-m1-hw-3-a.html#question-4",
    "title": "Homework 3",
    "section": "Question 4",
    "text": "Question 4\nFind the 5 employees with the highest “Regular Gross Paid” and calculate their average “OT Hours”. Also, reset the index if you have changed it previously.\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-5",
    "href": "danl-m1-hw-3-a.html#question-5",
    "title": "Homework 3",
    "section": "Question 5",
    "text": "Question 5\nSort the DataFrame by “Fiscal Year” and “Total Other Pay” in descending order, then set “First Name” as the index and use the loc accessor to retrieve the “Total Other Pay” for a specific first name, say “MICHAEL”.\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-6",
    "href": "danl-m1-hw-3-a.html#question-6",
    "title": "Homework 3",
    "section": "Question 6",
    "text": "Question 6\n\nSelect employees who have “OT Hours” greater than 0, calculate their “OT Rate” (Total OT Paid / OT Hours), and then find the employee with the highest “OT Rate”. Display their full name and OT Rate.\n\nHint: Start with filtering observations in nyc_payroll with the following lines:\n\n\n\n# Boolean Series of whether or not 'OT Hours' is greater than 0.\npos_OT_hours = nyc_payroll['OT Hours'] &gt; 0 \n\n# Keeping only the observations with pos_OT_hours == True\nwith_ot = nyc_payroll[ pos_OT_hours ] \n\nAnswer"
  },
  {
    "objectID": "danl-m1-hw-3-a.html#question-7",
    "href": "danl-m1-hw-3-a.html#question-7",
    "title": "Homework 3",
    "section": "Question 7",
    "text": "Question 7\nSort the DataFrame first by “Work Location Borough” alphabetically, and then by “Total Compensation” (sum of “Base Salary” and “Total OT Paid”) in descending order within each borough.\nAnswer"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet’s read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-1",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-1",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-2",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-2",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation’s value is missing.\n\nIs a value of a variable “XYZ” missing?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-3",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-3",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation’s value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-4",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-4",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna=False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-5",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-5",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\",\n                  parse_dates = [\"Start Date\"])\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-6",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-6",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter’s default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-7",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-7",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-8",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-8",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-9",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-9",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-10",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-10",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-11",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-11",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method’s keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-12",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-12",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-13",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-13",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-14",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-14",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of variables that pandas should use to determine an observation’s uniqueness.\n\nThe above example finds the first occurrence of each unique value in the ‘Team’ variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-15",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-15",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-16",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-16",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value’s last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of “Douglas” and a Gender of “Male”. Then check which “Douglas” is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\n\nThe pandas library’s GroupBy object is a storage container for grouping observations into buckets.\nIt provides a set of methods to aggregate and analyze each independent group in the collection.\nIt allows us to extract observations at specific index positions within each group.\nIt also offers a convenient way to iterate over the groups of observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-1",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-1",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\n\nThe pandas library’s GroupBy object is a storage container for grouping observations into buckets.\nIt provides a set of methods to aggregate and analyze each independent group in the collection.\nIt allows us to extract observations at specific index positions within each group.\nIt also offers a convenient way to iterate over the groups of observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-2",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-2",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\npd.DataFrame() converts a List/Dictionary/Series into a DataFrame ojbect\n\n\n# Creating a dictionary\nfood_data = {\n\"Item\": [\"Apple\", \"Onion\", \"Orange\", \"Tomato\", \"Watermelon\"],\n\"Type\": [\"Fruit\", \"Vegie\", \"Fruit\", \"Vegie\", \"Fruit\"],\n\"Price\": [1.05, 1.00, 1.25, 0.85, 4.15]\n}\n\n# Converting a dictionary into a DataFrame\nsupermarket = pd.DataFrame(data = food_data)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-3",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-3",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\n\n\n\n\n\n\nThe Type variable identifies the group to which an Item belongs.\n\nThere are two groups of items in the supermarket data set: “Fruit” and “Vegie”.\nWe can use terms such as groups, buckets, and clusters interchangeably to describe the same idea.\nMultiple observations fall into the same category."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-4",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-4",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\n\n\n\n\n\n\nThe GroupBy object implicitly organizes observations into buckets based on shared values in a categorical variable."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-5",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-5",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\nSuppose that we are interested in the average price of a fruit and the average price of a vegie.\n\nIf we could isolate the “Fruit” observations and “Vegie” observations into separate groups, it would be easier to perform the calculations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-6",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-6",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\nLet’s begin by invoking the groupby() method on the supermarket DataFrame.\n\nWe need to pass groupby() a categorical variable whose values will be used to create the groups.\n\n\n\ngroups = supermarket.groupby(\"Type\")\ngroups\n\nThe DataFrameGroupBy object is separate and distinct from a DataFrame"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-7",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-7",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\nThe “Type” variable has two unique values, so the GroupBy object will store two groups.\n\n\ngroups.get_group(\"Fruit\")\ngroups.get_group(\"Vegie\")\n\nThe get_group() method accepts a group name and returns a DataFrame with the corresponding observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-8",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-8",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy Object\n\n\nOur original goal was to calculate the average price of the fruits and vegetables in supermarket.\n\n\ngroups.mean()\n\nWith a few lines of code, we have successfully split, aggregated, and analyzed a data set"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-9",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-9",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nFortune 1000 dataset\n\n\nThe Fortune 1000 is a listing of the 1,000 largest companies in the United States by revenue.\n\nThe list is updated annually by the business magazine Fortune.\nThe fortune_2023.csv file is a collection of Fortune 1000 companies from 2023 (Source: Kaggle).\n\n\n\nfortune1000 = pd.read_csv(\"https://bcdanl.github.io/data/fortune_2023.csv\")\n\nvarlist = ['Company', 'Revenues_M', 'Profits_M', 'Number_of_employees', 'Sector', 'Industry']\nfortune = fortune1000[varlist]\n\nA sector can have many companies; An industry is a subcategory within a sector.\nLet’s explore the fortune DataFrame.\n\nHow many unique sectors are in fortune?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-10",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-10",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy object from a dataset\n\n\nLet’s pull out all companies with a Sector value of \"Retailing\".\n\nThen, calculate the Retailing sector’s average revenue:\n\n\n\nin_retailing = ( fortune[\"Sector\"] == \"Retailing\" )\nretail_companies = fortune[ in_retailing ]\nretail_companies[\"Revenues\"].mean()\n\nWithout a group operation, we may need to write a lot of additional code to apply the same logic to the other 20 sectors in fortune.\n\nPandas’ GroupBy object offers the best solution out of the box."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-11",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-11",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nCreating a GroupBy object from a dataset\nsectors = fortune.groupby(\"Sector\")\nlen(sectors)    # fortune[\"Sector\"].nunique()\nsectors.size()\n\nWe can count the number of groups in sectors by passing the GroupBy object into the Python’s built-in len() function\nThe size() method on the GroupBy object returns a Series with an alphabetical list of the groups and their observation counts."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-12",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-12",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAttributes and methods of a GroupBy object\nsectors.groups\n\nThe groups attribute stores a dictionary with associations of group-to-observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-13",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-13",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAttributes and methods of a GroupBy object\n\n\nWhat if we want to find the highest-performing company (by revenue) within each sector?\n\n\nsectors.first()\nsectors.last()\n\nThe GroupBy object’s first()/last() method extracts the first/last observation listed for each group in a DataFrame.\n\nSince our fortune DataFrame is sorted by Revenue_M, the first company pulled out for each sector will be the highest-performing company within that sector."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-14",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-14",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAttributes and methods of a GroupBy object\nsectors.nth(0)\nsectors.nth(1)\nfortune[fortune[\"Sector\"] == \"Apparel\"]\n\nThe nth() method is used with a GroupBy object to select the nth observation from each group.\n\nHere we can confirm the output is correct by filtering for the “Apparel” observations in fortune."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-15",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-15",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAttributes and methods of a GroupBy object\nsectors.head(2)\nsectors.tail(2)\n\nThe head(n)/tail(n) method extracts the first/last n observations from each group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-16",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-16",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAttributes and methods of a GroupBy object\nsectors.get_group(\"Energy\")\ntype( sectors.get_group(\"Energy\") )\n\nWe can use the get_group() method to extract all observations in a given group.\n\nThe method returns a DataFrame containing the observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-17",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-17",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAggregation\n\n\nWe can invoke methods on the GroupBy object to apply aggregate operations to every group.\n\nAggregation is the process of taking multiple values and returning a single value.\n\n\n\nsectors.sum()\nsectors.mean()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-18",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-18",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAggregation\nsectors[\"Revenues_M\"]\nsectors[\"Revenues\"].sum()\nsectors[\"Revenues\"].mean()\nsectors[\"Revenues\"].max()\nsectors[\"Revenues\"].min()\n\nWe can target a single variable by passing its name inside square brackets after the GroupBy object.\n\nPandas returns a new object, a SeriesGroupBy."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-19",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-19",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAggregation\nsectors.agg(\n  Revenues_M_min = (\"Revenues_M\", \"min\"),\n  Profits_M_max = (\"Profits_M\", \"max\"),\n  Number_of_employees_mean = (\"Revenues_M\", \"mean\")\n)\n\nThe agg method applies multiple aggregate operations to different variables and can accept a tuple as its argument."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-20",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-20",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAggregation\nsectors[\"Revenues_M\"].agg(\"mean\")\n\nThe agg() method can also be used on a Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-21",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-21",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nAggregation\n\n\n\n\nWe pass in whatever aggregation we want.\n\nSome common options are in the table above."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-22",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-22",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nApplying a Custom Operation to All Groups\n\n\nSuppose that we want to apply a custom operation to each group in a GroupBy object.\n\nFor practice, let’s now shuffle observations in fortune.\n\n\n\nfortune = (\n    fortune\n    .sample( frac = 1 )\n    .reset_index( drop = True )\n)\n\nsample(frac=1): This samples 100% of the observations from the DataFrame, effectively shuffling it.\n\nThe frac parameter specifies the fraction of observations to return in the random sample, so frac=1 means “return all observations”."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-23",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-23",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nApplying a Custom Operation to All Groups\n\n\nSuppose that we want to apply a custom operation to each group in a GroupBy object.\n\nFor practice, let’s now shuffle observations in fortune.\n\n\n\nfortune_shuffled = (\n    fortune\n    .sample( frac = 1 )\n    .reset_index( drop = True )\n)\n\nreset_index(): This resets the index of the DataFrame.\n\nThe drop = True option is used to prevent the old index from being added as a variable in the new DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-24",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-24",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nLet’s do Questions 1-6 in Part 2 of Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-25",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-25",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nApplying a Custom Operation to All Groups\n\nHow can we identify top 5 companies in each sector?\n\nsort_values() with groupby()\nnlargest() with groupby()\n\nHowever, DataFrameGroupBy has no methods sort_values() or nlargest()."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-26",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-26",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nApplying a Custom Operation to All Groups\n\n\nHow can we apply the nlargest() method to each group?\n\nFirst, define a custom function that accepts a single argument: a DataFrame.\nSecond, pass the apply() method the custom function.\n\n\n\ndef get_largest_obs(df):\n    return df.nlargest(1, \"Revenues_M\", keep=\"all\")\n    \nsectors.apply(get_largest_obs)\n\nWe can use the apply() method when pandas does not support a custom aggregation we would like to apply to each group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-27",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-27",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nGrouping by Multiple Variables\nsector_and_industry = fortune.groupby([\"Sector\", \"Industry\"])\n\nWe can create a GroupBy object with values from multiple variables.\n\nThis operation is optimal when a combination of variables serves as the best identifier for a group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-28",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-28",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nGrouping by Multiple Variables\n(\n    sector_and_industry\n    .size()\n    .reset_index(name = \"n\")\n)\n\nThe GroupBy object’s size() method now returns a MultiIndex Series with a count of observations for each internal group.\nThe reset_index() method can be used to convert a Series into a DataFrame.\n\nThe name option renames a variable of index when resetting index."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#primer-on-custom-functions",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#primer-on-custom-functions",
    "title": "Lecture 5",
    "section": "Primer on Custom Functions",
    "text": "Primer on Custom Functions\n\nA function can take any number and type of input parameters and return any number and type of output results.\nWe can do two things with a function:\n\nDefine it\nCall it"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#primer-on-custom-functions-1",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#primer-on-custom-functions-1",
    "title": "Lecture 5",
    "section": "Primer on Custom Functions",
    "text": "Primer on Custom Functions\n\n\nTo define a Python function, we type def, the function name, parentheses enclosing any input parameters to the function, and then finally, a colon (:).\nLet’s define a very simple function my_half() that has a parameter x and returns a value x / 2.\n\n\ndef my_half(x):\n    return x / 2\n\nThe values we pass into the function when we call it are known as arguments.\nWhen we call a function with arguments, the values of those arguments are copied to their corresponding parameters inside the function."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-29",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-29",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nGrouping by Multiple Variables\nsector_and_industry.get_group((\"Business Services\", \"Financial Data Services\"))\n\nThe get_group() method requires a tuple of values to extract a nested DataFrame from the GroupBy collection."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-30",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-30",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nGrouping by Multiple Variables\nsector_and_industry.sum()\nsector_and_industry[\"Revenues_M\"].mean()\n\n(\n    sector_and_industry[\"Revenues_M\"]\n    .mean()\n    .reset_index(name = \"Revenues_mean\")\n)\n\nFor all aggregations, pandas returns a MultiIndex DataFrame with the calculations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\n\nThe pandas library’s GroupBy object is a storage container for grouping observations into buckets.\nIt provides a set of methods to aggregate and analyze each independent group in the collection.\nIt allows us to extract observations at specific index positions within each group.\nIt also offers a convenient way to iterate over the groups of observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-1",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-1",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\n\nThe pandas library’s GroupBy object is a storage container for grouping observations into buckets.\nIt provides a set of methods to aggregate and analyze each independent group in the collection.\nIt allows us to extract observations at specific index positions within each group.\nIt also offers a convenient way to iterate over the groups of observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-2",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-2",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\npd.DataFrame() converts a List/Dictionary/Series into a DataFrame ojbect\n\n\n# Creating a dictionary\nfood_data = {\n\"Item\": [\"Apple\", \"Onion\", \"Orange\", \"Tomato\", \"Watermelon\"],\n\"Type\": [\"Fruit\", \"Vegie\", \"Fruit\", \"Vegie\", \"Fruit\"],\n\"Price\": [1.05, 1.00, 1.25, 0.85, 4.15]\n}\n\n# Converting a dictionary into a DataFrame\nsupermarket = pd.DataFrame(data = food_data)"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-3",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-3",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\n\n\n\n\n\n\nThe Type variable identifies the group to which an Item belongs.\n\nThere are two groups of items in the supermarket data set: “Fruit” and “Vegie”.\nWe can use terms such as groups, buckets, and clusters interchangeably to describe the same idea.\nMultiple observations fall into the same category."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-4",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-4",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\n\n\n\n\n\n\nThe GroupBy object implicitly organizes observations into buckets based on shared values in a categorical variable.\n\nSuppose that we are interested in the average price of a fruit and the average price of a vegie.\nIf we could isolate the “Fruit” observations and “Vegie” observations into separate groups, it would be easier to perform the calculations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-5",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-5",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\nLet’s begin by invoking the groupby() method on the supermarket DataFrame.\n\nWe need to pass groupby() a categorical variable whose values will be used to create the groups.\n\n\n\ngroups = supermarket.groupby(\"Type\")\ngroups\n\nThe DataFrameGroupBy object is separate and distinct from a DataFrame"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-6",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-6",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\nThe “Type” variable has two unique values, so the GroupBy object will store two groups.\n\n\ngroups.get_group(\"Fruit\")\ngroups.get_group(\"Vegie\")\n\nThe get_group() method accepts a group name and returns a DataFrame with the corresponding observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-7",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-7",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy Object\n\n\nOur original goal was to calculate the average price of the fruits and vegetables in supermarket.\n\n\ngroups.mean()\n\nWith a few lines of code, we have successfully split, aggregated, and analyzed a data set"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-8",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-8",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nFortune 1000 dataset\n\n\nThe Fortune 1000 is a listing of the 1,000 largest companies in the United States by revenue.\n\nThe list is updated annually by the business magazine Fortune.\nThe fortune_2023.csv file is a collection of Fortune 1000 companies from 2023 (Source: Kaggle).\n\n\n\nfortune1000 = pd.read_csv(\"https://bcdanl.github.io/data/fortune_2023.csv\")\n\nvarlist = ['Company', 'Revenues_M', 'Profits_M', 'Number_of_employees', 'Sector', 'Industry']\nfortune = fortune1000[varlist]\n\nA sector can have many companies; An industry is a subcategory within a sector.\nLet’s explore the fortune DataFrame.\n\nHow many unique sectors are in fortune?"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-9",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-9",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy object from a dataset\n\n\nLet’s pull out all companies with a Sector value of \"Retailing\".\n\nThen, calculate the Retailing sector’s average revenue:\n\n\n\nin_retailing = ( fortune[\"Sector\"] == \"Retailing\" )\nretail_companies = fortune[ in_retailing ]\nretail_companies[\"Revenues\"].mean()\n\nWithout a group operation, we may need to write a lot of additional code to apply the same logic to the other 20 sectors in fortune.\n\nPandas’ GroupBy object offers the best solution out of the box."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-10",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-10",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nCreating a GroupBy object from a dataset\nsectors = fortune.groupby(\"Sector\")\nlen(sectors)    # fortune[\"Sector\"].nunique()\nsectors.size()\n\nWe can count the number of groups in sectors by passing the GroupBy object into the Python’s built-in len() function\nThe size() method on the GroupBy object returns a Series with an alphabetical list of the groups and their observation counts."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-11",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-11",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAttributes and methods of a GroupBy object\nsectors.groups\n\nThe groups attribute stores a dictionary with associations of group-to-observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-12",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-12",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAttributes and methods of a GroupBy object\n\n\nWhat if we want to find the highest-performing company (by revenue) within each sector?\n\n\nsectors.first()\nsectors.last()\n\nThe GroupBy object’s first()/last() method extracts the first/last observation listed for each group in a DataFrame.\n\nSince our fortune DataFrame is sorted by Revenue_M, the first company pulled out for each sector will be the highest-performing company within that sector."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-13",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-13",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAttributes and methods of a GroupBy object\nsectors.nth(0)\nsectors.nth(1)\nfortune[fortune[\"Sector\"] == \"Apparel\"]\n\nThe nth() method is used with a GroupBy object to select the nth observation from each group.\n\nHere we can confirm the output is correct by filtering for the “Apparel” observations in fortune."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-14",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-14",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAttributes and methods of a GroupBy object\nsectors.head(2)\nsectors.tail(2)\n\nThe head(n)/tail(n) method extracts the first/last n observations from each group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-15",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-15",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAttributes and methods of a GroupBy object\nsectors.get_group(\"Energy\")\ntype( sectors.get_group(\"Energy\") )\n\nWe can use the get_group() method to extract all observations in a given group.\n\nThe method returns a DataFrame containing the observations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-16",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-16",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAggregation\n\n\nWe can invoke methods on the GroupBy object to apply aggregate operations to every group.\n\nAggregation is the process of taking multiple values and returning a single value.\n\n\n\nsectors.sum()\nsectors.mean()"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-17",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-17",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAggregation\nsectors[\"Revenues_M\"]\nsectors[\"Revenues\"].sum()\nsectors[\"Revenues\"].mean()\nsectors[\"Revenues\"].max()\nsectors[\"Revenues\"].min()\n\nWe can target a single variable by passing its name inside square brackets after the GroupBy object.\n\nPandas returns a new object, a SeriesGroupBy."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-18",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-18",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAggregation\nsectors.agg(\n  Revenues_M_min = (\"Revenues_M\", \"min\"),\n  Profits_M_max = (\"Profits_M\", \"max\"),\n  Number_of_employees_mean = (\"Revenues_M\", \"mean\")\n)\n\nThe agg method applies multiple aggregate operations to different variables and can accept a tuple as its argument."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-19",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-19",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAggregation\nsectors[\"Revenues_M\"].agg(\"mean\")\n\nThe agg() method can also be used on a Series."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-20",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-20",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nAggregation\n\n\n\n\nWe pass in whatever aggregation we want.\n\nSome common options are in the table above."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-21",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-21",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nApplying a Custom Operation to All Groups\n\n\nSuppose that we want to apply a custom operation to each group in a GroupBy object.\n\nFor practice, let’s now shuffle observations in fortune.\n\n\n\nfortune = (\n    fortune\n    .sample( frac = 1 )\n    .reset_index( drop = True )\n)\n\nsample(frac=1): This samples 100% of the observations from the DataFrame, effectively shuffling it.\n\nThe frac parameter specifies the fraction of observations to return in the random sample, so frac=1 means “return all observations”."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-22",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-22",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nApplying a Custom Operation to All Groups\n\n\nSuppose that we want to apply a custom operation to each group in a GroupBy object.\n\nFor practice, let’s now shuffle observations in fortune.\n\n\n\nfortune_shuffled = (\n    fortune\n    .sample( frac = 1 )\n    .reset_index( drop = True )\n)\n\nreset_index(): This resets the index of the DataFrame.\n\nThe drop = True option is used to prevent the old index from being added as a variable in the new DataFrame."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-23",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-23",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nLet’s do Questions 1-6 in Part 2 of Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-24",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-24",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nApplying a Custom Operation to All Groups\n\nHow can we identify top 5 companies in each sector?\n\nsort_values() with groupby()\nnlargest() with groupby()\n\nHowever, DataFrameGroupBy has no methods sort_values() or nlargest()."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-25",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-25",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nApplying a Custom Operation to All Groups\n\n\nHow can we apply the nlargest() method to each group?\n\nFirst, define a custom function that accepts a single argument: a DataFrame.\nSecond, pass the apply() method the custom function.\n\n\n\ndef get_largest_obs(df):\n    return df.nlargest(1, \"Revenues_M\", keep=\"all\")\n    \nsectors.apply(get_largest_obs)\n\nWe can use the apply() method when pandas does not support a custom aggregation we would like to apply to each group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-26",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-26",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nApplying a Custom Operation to All Groups\ndef get_nlargest_obs(df, n, var):\n  return df.nlargest(n, var, keep = \"all\")\n\nsectors.apply(get_nlargest_obs, 2, \"Revenues_M\").reset_index(drop=True)\n\nA custom function can take a multiple parameters.\n\nWhen applying a custom function with multiple parameters to a GroupBy object, we need to provide the rest of arguments to the apply() method."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-27",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-27",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nGrouping by Multiple Variables\nsector_and_industry = fortune.groupby([\"Sector\", \"Industry\"])\n\nWe can create a GroupBy object with values from multiple variables.\n\nThis operation is optimal when a combination of variables serves as the best identifier for a group."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-28",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-28",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nGrouping by Multiple Variables\n(\n    sector_and_industry\n    .size()\n    .reset_index(name = \"n\")\n)\n\nThe GroupBy object’s size() method now returns a MultiIndex Series with a count of observations for each internal group.\nThe reset_index() method can be used to convert a Series into a DataFrame.\n\nThe name option renames a variable of index when resetting index."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-29",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-29",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nGrouping by Multiple Variables\nsector_and_industry.get_group((\"Business Services\", \"Financial Data Services\"))\n\nThe get_group() method requires a tuple of values to extract a nested DataFrame from the GroupBy collection."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-30",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-30",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nGrouping by Multiple Variables\nsector_and_industry.sum()\nsector_and_industry[\"Revenues_M\"].mean()\n\n(\n    sector_and_industry[\"Revenues_M\"]\n    .mean()\n    .reset_index(name = \"Revenues_mean\")\n)\n\nFor all aggregations, pandas returns a MultiIndex DataFrame with the calculations."
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-31",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#grouped-operations-31",
    "title": "Lecture 5",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nLet’s do Question 7 in Part 2 of Classwork 5!"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-1",
    "href": "danl-cw/danl-m1-cw-5.html#question-1",
    "title": "Classwork 5",
    "section": "Question 1",
    "text": "Question 1\nFind all observations with a date_added value between January 1, 2019 and February 1, 2019.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-2",
    "href": "danl-cw/danl-m1-cw-5.html#question-2",
    "title": "Classwork 5",
    "section": "Question 2",
    "text": "Question 2\nDrop all observations with a NaN value in the director variable.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-3",
    "href": "danl-cw/danl-m1-cw-5.html#question-3",
    "title": "Classwork 5",
    "section": "Question 3",
    "text": "Question 3\nIdentify the days when Netflix added only one movie to its catalog.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-1-1",
    "href": "danl-cw/danl-m1-cw-5.html#question-1-1",
    "title": "Classwork 5",
    "section": "Question 1",
    "text": "Question 1\nGroup the cereals_oatmeal, using the Manufacturer variable.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-2-1",
    "href": "danl-cw/danl-m1-cw-5.html#question-2-1",
    "title": "Classwork 5",
    "section": "Question 2",
    "text": "Question 2\nDetermine the total number of groups, and the number of cereals per group.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-3-1",
    "href": "danl-cw/danl-m1-cw-5.html#question-3-1",
    "title": "Classwork 5",
    "section": "Question 3",
    "text": "Question 3\nExtract the cereals that belong to the manufacturer \"Kellogg's\".\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-4",
    "href": "danl-cw/danl-m1-cw-5.html#question-4",
    "title": "Classwork 5",
    "section": "Question 4",
    "text": "Question 4\nCalculate the average of values in the Calories, Fiber, and Sugars variables for each manufacturer.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-5",
    "href": "danl-cw/danl-m1-cw-5.html#question-5",
    "title": "Classwork 5",
    "section": "Question 5",
    "text": "Question 5\nFind the maximum value in the Sugars variable for each manufacturer.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-6",
    "href": "danl-cw/danl-m1-cw-5.html#question-6",
    "title": "Classwork 5",
    "section": "Question 6",
    "text": "Question 6\nFind the minimum value in the Fiber variable for each manufacturer.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-m1-cw-5.html#question-7",
    "href": "danl-cw/danl-m1-cw-5.html#question-7",
    "title": "Classwork 5",
    "section": "Question 7",
    "text": "Question 7\nExtract the cereal with the lowest amount of grams of sugar per manufacturer in a new DataFrame.\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#variable-description",
    "href": "danl-hw/danl-m1-hw-5.html#variable-description",
    "title": "Homework 5",
    "section": "",
    "text": "The fao DataFrame contains the country-year level observation regarding variables below:\n\nSSA: A boolean indicating if the country is in Sub-Saharan Africa.\nArea: The name of the country.\nYear: The year of observation.\ngdp_per_capita: GDP per capita.\ndrinking_water: The percentage of the population with access to safe drinking water.\nsanitation_service: The percentage of the population with access to improved sanitation services.\nchildren_stunted: The percentage of children under 5 years old who are stunted.\nchildren_overweight: The percentage of children under 5 years old who are overweight.\ninvestment_pct: The percentage of GDP invested in public health."
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-1",
    "href": "danl-hw/danl-m1-hw-5.html#question-1",
    "title": "Homework 5",
    "section": "",
    "text": "What percentage of the values is missing for each variable?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-2",
    "href": "danl-hw/danl-m1-hw-5.html#question-2",
    "title": "Homework 5",
    "section": "",
    "text": "Fill missing values in the gdp_per_capita variable with the mean value of that variable.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-3",
    "href": "danl-hw/danl-m1-hw-5.html#question-3",
    "title": "Homework 5",
    "section": "",
    "text": "Drop observations where drinking_water or sanitation_service information is missing.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-4",
    "href": "danl-hw/danl-m1-hw-5.html#question-4",
    "title": "Homework 5",
    "section": "",
    "text": "What is the average drinking_water access percentage for each Area grouped by SSA status?\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-5",
    "href": "danl-hw/danl-m1-hw-5.html#question-5",
    "title": "Homework 5",
    "section": "",
    "text": "Calculate the mean sanitation_service percentage for each combination of SSA status and Year.\nHint: We can group a DataFrame by a list of multiple variables. Then, each group corresponds to a unique combination of values across the specified variables.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-5-1",
    "href": "danl-hw/danl-m1-hw-5.html#question-5-1",
    "title": "Homework 5",
    "section": "",
    "text": "For each year, find the 5 worst countries in terms of drinking_water.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-6",
    "href": "danl-hw/danl-m1-hw-5.html#question-6",
    "title": "Homework 5",
    "section": "",
    "text": "For each year, find the 5 worst countries in terms of drinking_water.\n\nHint: We can start with the sort_values() method.\nNote: DataFrameGroupBy does not support the sort_values() method.\n\nAnswer"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-17",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#pandas-basics-17",
    "title": "Lecture 5",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet’s do Questions 1-3 in Part 1 of Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-31",
    "href": "danl-lec/danl-m1-lec-05-2024-0305.html#group-operations-31",
    "title": "Lecture 5",
    "section": "Group Operations",
    "text": "Group Operations\nLet’s do Question 7 in Part 2 of Classwork 5!"
  },
  {
    "objectID": "danl-hw/danl-m1-hw-5.html#question-7",
    "href": "danl-hw/danl-m1-hw-5.html#question-7",
    "title": "Homework 5",
    "section": "",
    "text": "For each year, find the 5 worst countries in terms of children_stunted.\nAnswer"
  }
]